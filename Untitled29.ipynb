{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/safwanahmadsaffi/AI-and-Python-Programming-Language/blob/main/Untitled29.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESULT IS 71 APPROX\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "P_ft4S7_087-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y3cVQwV8STa9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import numpy as np\n",
        "\n",
        "# Feature engineering function\n",
        "def add_extra_features(df):\n",
        "    # identify numeric features excluding ID and target columns\n",
        "    features = [col for col in df.columns if col not in ['ID'] and not col.startswith('BlendProperty')]\n",
        "    df['feature_sum'] = df[features].sum(axis=1)\n",
        "    df['feature_mean'] = df[features].mean(axis=1)\n",
        "    df['feature_std'] = df[features].std(axis=1)\n",
        "    return df\n",
        "\n",
        "# Load the datasets\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "print(f\"Train data shape: {train_df.shape}\")\n",
        "print(f\"Test data shape: {test_df.shape}\")\n",
        "print(f\"Train columns: {list(train_df.columns)}\")\n",
        "print(f\"Test columns: {list(test_df.columns)}\")\n",
        "\n",
        "# Separate features (X) and target variables (y)\n",
        "X_train = train_df.drop([f\"BlendProperty{i}\" for i in range(1, 11)], axis=1)\n",
        "y_train = train_df[[f\"BlendProperty{i}\" for i in range(1, 11)]]\n",
        "\n",
        "# For the test set, drop the 'ID' column\n",
        "X_test = test_df.drop(\"ID\", axis=1)\n",
        "\n",
        "# Add extra statistical features to improve model\n",
        "X_train = add_extra_features(X_train)\n",
        "X_test = add_extra_features(X_test)\n",
        "\n",
        "# Initialize models for ensemble\n",
        "gb_model = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=4, random_state=42)\n",
        "knn_model = KNeighborsRegressor(n_neighbors=7)\n",
        "\n",
        "# Prepare container for predictions\n",
        "predictions = np.zeros((X_test.shape[0], y_train.shape[1]))\n",
        "\n",
        "# Cross-validation setup\n",
        "gkf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for i, col in enumerate(y_train.columns):\n",
        "    print(f\"Training and validating model for {col}\")\n",
        "    cv_scores = []\n",
        "    for train_idx, val_idx in gkf.split(X_train):\n",
        "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "        y_tr, y_val = y_train[col].iloc[train_idx], y_train[col].iloc[val_idx]\n",
        "        gb_model.fit(X_tr, y_tr)\n",
        "        preds = gb_model.predict(X_val)\n",
        "        cv_scores.append(mean_absolute_percentage_error(y_val, preds))\n",
        "    print(f\"{col} CV MAPE: {np.mean(cv_scores):.5f}\")\n",
        "    # Train on full data\n",
        "    gb_model.fit(X_train, y_train[col])\n",
        "    knn_model.fit(X_train, y_train[col])\n",
        "    preds_gb = gb_model.predict(X_test)\n",
        "    preds_knn = knn_model.predict(X_test)\n",
        "    predictions[:, i] = (preds_gb + preds_knn) / 2\n",
        "\n",
        "# Create and save submission\n",
        "submission_df = pd.DataFrame(predictions, columns=[f\"BlendProperty{i}\" for i in range(1, 11)])\n",
        "submission_df.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Ensembled model trained and predictions saved to submission.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESULT IS 50 APPROX\n"
      ],
      "metadata": {
        "id": "9nXbhX0v1J0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "# STEP 2: Load the datasets\n",
        "train = pd.read_csv(\"/content/train.csv\")\n",
        "test = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "# STEP 3: Separate features and targets\n",
        "# Drop 'ID' from test set and BlendProperty columns from train set\n",
        "X_train = train.drop([f\"BlendProperty{i}\" for i in range(1, 11)], axis=1)\n",
        "y_train = train[[f\"BlendProperty{i}\" for i in range(1, 11)]]\n",
        "X_test = test.drop(\"ID\", axis=1)\n",
        "\n",
        "\n",
        "# STEP 4: Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Optional: convert back to DataFrame\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
        "\n",
        "# STEP 5: Split train data for validation\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# STEP 6: Train Random Forest Model\n",
        "rf_model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "rf_model.fit(X_tr, y_tr)\n",
        "\n",
        "# STEP 7: Validate on validation set\n",
        "y_val_pred = rf_model.predict(X_val)\n",
        "mape = mean_absolute_percentage_error(y_val, y_val_pred)\n",
        "print(f\"Validation MAPE: {mape:.4f}\")\n",
        "\n",
        "# STEP 8: Predict on test set\n",
        "y_test_pred = rf_model.predict(X_test_scaled)\n",
        "\n",
        "# STEP 9: Create submission DataFrame\n",
        "submission = pd.DataFrame(y_test_pred, columns=[f\"BlendProperty{i}\" for i in range(1, 11)])\n",
        "submission.insert(0, 'ID', test['ID'])  # Ensure 'ID' is the first column\n",
        "\n",
        "# STEP 10: Save to CSV\n",
        "submission.to_csv(\"random_forest_submission.csv\", index=False)\n",
        "print(\"✅ Submission file saved as 'random_forest_submission.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0cD12ZtkKW0",
        "outputId": "3eb3238a-56dd-4f57-ae52-113f6f203c2a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation MAPE: 4.2471\n",
            "✅ Submission file saved as 'random_forest_submission.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESULT IS 71 APPROX\n"
      ],
      "metadata": {
        "id": "5iKcdl_z1TNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Libraries\n",
        "import pandas as pd, numpy as np, hashlib, optuna, lightgbm as lgb\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 2. Load\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test  = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# 3. Basic split\n",
        "X_base_train = train.iloc[:, :55].copy()\n",
        "y_train      = train.iloc[:, 55:].copy()\n",
        "X_base_test  = test.iloc[:, :55].copy() # Keep ID for now to merge later\n",
        "\n",
        "\n",
        "# 4. === Feature Engineering =================================================\n",
        "def add_features(df):\n",
        "    out = df.copy()\n",
        "\n",
        "    # component fraction columns = first 5\n",
        "    frac_cols = [f\"Component{i}_fraction\" for i in range(1, 6)]\n",
        "\n",
        "\n",
        "    # --- weighted component-property: (fraction_i * Component_i_Property_j)\n",
        "    for comp in range(1, 6):          # Components 1..5\n",
        "        frac_col = f\"Component{comp}_fraction\"\n",
        "        if frac_col in df.columns: # Ensure the fraction column exists\n",
        "            for prop in range(1, 11):     # Properties 1..10\n",
        "                prop_col = f\"Component{comp}_Property{prop}\"\n",
        "                new_col  = f\"W_{prop_col}\"\n",
        "                # Check if the property column exists in the current DataFrame before using it\n",
        "                if prop_col in df.columns:\n",
        "                    out[new_col] = df[frac_col] * df[prop_col]\n",
        "                else:\n",
        "                    # If property column is missing, create the weighted column with zeros\n",
        "                    out[new_col] = 0\n",
        "\n",
        "\n",
        "    # --- simple pairwise fraction interactions\n",
        "    for i in range(1, 6):\n",
        "        for j in range(i+1, 6):\n",
        "            frac_i_col = f\"Component{i}_fraction\"\n",
        "            frac_j_col = f\"Component{j}_fraction\"\n",
        "            if frac_i_col in df.columns and frac_j_col in df.columns:\n",
        "                 out[f\"Frac_{i}_{j}\"] = df[frac_i_col] * df[frac_j_col]\n",
        "            else:\n",
        "                out[f\"Frac_{i}_{j}\"] = 0\n",
        "\n",
        "\n",
        "    return out\n",
        "\n",
        "# Drop 'ID' from test features before adding features\n",
        "X_train = add_features(X_base_train)\n",
        "X_test  = add_features(X_base_test.drop(\"ID\", axis=1))\n",
        "\n",
        "\n",
        "# 5. Scaling numeric columns (LightGBM doesn't need it, but interactions benefit)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Ensure X_test has the same columns as X_train before scaling\n",
        "# Add missing columns to X_test and fill with 0\n",
        "missing_cols_in_test = set(X_train.columns) - set(X_test.columns)\n",
        "for c in missing_cols_in_test:\n",
        "    X_test[c] = 0\n",
        "# Reorder columns to match X_train\n",
        "X_test = X_test[X_train.columns]\n",
        "\n",
        "\n",
        "X_test_scaled  = scaler.transform(X_test)\n",
        "\n",
        "# Re‑wrap as DataFrame for convenience\n",
        "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "X_test  = pd.DataFrame(X_test_scaled,  columns=X_test.columns)\n",
        "\n",
        "# 6. GroupKFold for robust CV  (group by rounded fractions hash)\n",
        "def hash_frac(row, precision=2):\n",
        "    # Ensure we only use the fraction columns for hashing\n",
        "    frac_values = row[[f\"Component{i}_fraction\" for i in range(1, 6)]]\n",
        "    key = tuple(np.round(frac_values, precision))\n",
        "    return int(hashlib.md5(str(key).encode()).hexdigest(), 16) % 10_000_000\n",
        "\n",
        "# Apply hash_frac to the original X_base_train to get groups\n",
        "groups = X_base_train.apply(hash_frac, axis=1)\n",
        "\n",
        "\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "\n",
        "# 7. LightGBM + Optuna tuner for ONE target; wrap in a function\n",
        "def tune_and_train(X, y, target_name):\n",
        "    def objective(trial):\n",
        "        params = {\n",
        "            \"objective\": \"rmse\",\n",
        "            \"metric\": \"mae\",\n",
        "            \"verbosity\": -1,\n",
        "            \"boosting_type\": \"gbdt\",\n",
        "            \"learning_rate\": trial.suggest_float(\"lr\", 0.01, 0.2, log=True),\n",
        "            \"num_leaves\": trial.suggest_int(\"leaves\", 31, 1023, log=True),\n",
        "            \"feature_fraction\": trial.suggest_float(\"feat_frac\", 0.5, 1.0),\n",
        "            \"bagging_fraction\": trial.suggest_float(\"bag_frac\", 0.5, 1.0),\n",
        "            \"bagging_freq\": 1,\n",
        "            \"min_data_in_leaf\": trial.suggest_int(\"min_leaf\", 20, 200),\n",
        "            \"lambda_l1\": trial.suggest_float(\"l1\", 0.0, 5.0),\n",
        "            \"lambda_l2\": trial.suggest_float(\"l2\", 0.0, 5.0),\n",
        "        }\n",
        "        mape_scores = []\n",
        "        for train_idx, val_idx in gkf.split(X, y, groups):\n",
        "            lgb_train = lgb.Dataset(X.iloc[train_idx], y.iloc[train_idx])\n",
        "            lgb_val   = lgb.Dataset(X.iloc[val_idx],  y.iloc[val_idx])\n",
        "            # Update lgb.train call to use callbacks for early stopping\n",
        "            model = lgb.train(params, lgb_train,\n",
        "                              valid_sets=[lgb_val],\n",
        "                              num_boost_round=500,\n",
        "                              callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]) # Use callbacks\n",
        "            preds = model.predict(X.iloc[val_idx])\n",
        "            mape_scores.append(mean_absolute_percentage_error(y.iloc[val_idx], preds))\n",
        "        return np.mean(mape_scores)\n",
        "\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, n_trials=20, show_progress_bar=False)\n",
        "\n",
        "    best_params = study.best_trial.params\n",
        "    best_params.update({\"objective\": \"rmse\", \"metric\": \"mae\", \"verbosity\": -1})\n",
        "    # Update final lgb.train call to use callbacks for early stopping if needed,\n",
        "    # but since we train on the full data here, early stopping isn't typically used\n",
        "    # and the num_boost_round is taken from the best iteration from Optuna.\n",
        "    # If Optuna's best iteration is not available, default to 500 rounds.\n",
        "    final_model = lgb.train(best_params, lgb.Dataset(X, y),\n",
        "                            num_boost_round=study.best_trial.user_attrs.get(\"best_iteration\", 500))\n",
        "    return final_model, study.best_value\n",
        "\n",
        "# 8. Train one model per target\n",
        "models, val_mapes = {}, {}\n",
        "for target in y_train.columns:\n",
        "    model, best_mape = tune_and_train(X_train, y_train[target], target)\n",
        "    models[target] = model\n",
        "    val_mapes[target] = best_mape\n",
        "    print(f\"{target}: CV‑MAPE {best_mape:.4f}\")\n",
        "\n",
        "print(f\"\\nMean CV‑MAPE over all targets: {np.mean(list(val_mapes.values())):.4f}\")\n",
        "\n",
        "# 9. Predict on test\n",
        "test_preds = pd.DataFrame({t: m.predict(X_test) for t, m in models.items()})\n",
        "\n",
        "# 10. Build submission\n",
        "submission = test_preds.copy()\n",
        "submission.insert(0, \"ID\", test[\"ID\"])\n",
        "submission.to_csv(\"lightgbm_optuna_submission.csv\", index=False)\n",
        "print(\"\\n✅  Submission saved as 'lightgbm_optuna_submission.csv'\")"
      ],
      "metadata": {
        "id": "Qkqnk-BkmaI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13d24963",
        "outputId": "5380a558-f005-4e06-db4d-87f07c9026e7"
      },
      "source": [
        "%pip install optuna"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.2-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.2 colorlog-6.9.0 optuna-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "# blend_prediction.py\n",
        "# Shell.ai Hackathon – Fuel‑Blend Properties Prediction\n",
        "# Author: Safwan (stock‑gpt) – July 2025\n",
        "\n",
        "import os, hashlib, warnings\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "import lightgbm as lgb\n",
        "# Removed CatBoost for now to simplify debugging\n",
        "from catboost import CatBoostRegressor\n",
        "import optuna, joblib, json, random\n",
        "import sys\n",
        "import re\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# Hardcoded parameters for Colab execution\n",
        "TRAIN_FILE = \"train.csv\"\n",
        "TEST_FILE = \"test.csv\"\n",
        "SUBMISSION_FILE = \"lightgbm_optuna_submission.csv\"\n",
        "OPTUNA_TRIALS = 20 # Reduced trials for faster testing\n",
        "LGB_WEIGHT = 0.6 # Hardcoded LightGBM weight\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. Load\n",
        "# ------------------------------------------------------------------------------\n",
        "# Replaced args.train and args.test with hardcoded variables\n",
        "train = pd.read_csv(TRAIN_FILE)\n",
        "test  = pd.read_csv(TEST_FILE)\n",
        "\n",
        "X_base_train = train.iloc[:, :55].copy()\n",
        "y_train      = train.iloc[:, 55:].copy()\n",
        "X_base_test  = test.iloc[:, :55].copy()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. Feature engineering\n",
        "# ------------------------------------------------------------------------------\n",
        "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    # weighted component‑property\n",
        "    for comp in range(1, 6):\n",
        "        f_col = f\"Component{comp}_fraction\"\n",
        "        if f_col not in df: continue\n",
        "        for prop in range(1, 11):\n",
        "            p_col = f\"Component{comp}_Property{prop}\"\n",
        "            new_c = f\"W_{p_col}\"\n",
        "            out[new_c] = df[f_col] * df.get(p_col, 0)\n",
        "    # pairwise fraction interactions\n",
        "    for i in range(1, 6):\n",
        "        for j in range(i+1, 6):\n",
        "            fi, fj = f\"Component{i}_fraction\", f\"Component{j}_fraction\"\n",
        "            out[f\"Frac_{i}_{j}\"] = df.get(fi, 0) * df.get(fj, 0)\n",
        "    return out\n",
        "\n",
        "X_train = add_features(X_base_train)\n",
        "X_test  = add_features(X_base_test)\n",
        "\n",
        "# ensure same columns order\n",
        "missing = set(X_train.columns) - set(X_test.columns)\n",
        "for c in missing: X_test[c] = 0\n",
        "X_test = X_test[X_train.columns]\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. Scaling\n",
        "# ------------------------------------------------------------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled  = scaler.transform(X_test)\n",
        "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "X_test  = pd.DataFrame(X_test_scaled,  columns=X_test.columns)\n",
        "\n",
        "# Sanitize column names for LightGBM compatibility\n",
        "def sanitize_col_names(df):\n",
        "    cols = df.columns\n",
        "    new_cols = []\n",
        "    for col in cols:\n",
        "        new_col = re.sub(r'\\W+', '_', col) # Replace non-word characters with underscore\n",
        "        new_cols.append(new_col)\n",
        "    df.columns = new_cols\n",
        "    return df\n",
        "\n",
        "X_train = sanitize_col_names(X_train)\n",
        "X_test = sanitize_col_names(X_test)\n",
        "\n",
        "\n",
        "# 5. GroupKFold groups (hash of fractions)\n",
        "# ------------------------------------------------------------------------------\n",
        "def hash_frac(row, prec=2):\n",
        "    key = tuple(np.round(row[[f\"Component{i}_fraction\" for i in range(1,6)]], prec))\n",
        "    return int(hashlib.md5(str(key).encode()).hexdigest(),16)%10_000_000\n",
        "\n",
        "groups = X_base_train.apply(hash_frac, axis=1)\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 6. LightGBM + Optuna tuning (bag 5 folds)\n",
        "# ------------------------------------------------------------------------------\n",
        "# Check for GPU availability using CatBoost's method for consistency\n",
        "has_gpu = False # Default to False\n",
        "try:\n",
        "    # Attempt to use CatBoost's check if CatBoostRegressor is available\n",
        "    from catboost import CatBoostRegressor\n",
        "    has_gpu = CatBoostRegressor().get_param(\"task_type\")==\"GPU\" if os.getenv(\"CUDA_VISIBLE_DEVICES\") else False\n",
        "except ImportError:\n",
        "    # If CatBoost is not available, fall back to checking CUDA_VISIBLE_DEVICES\n",
        "    has_gpu = True if os.getenv(\"CUDA_VISIBLE_DEVICES\") else False\n",
        "\n",
        "\n",
        "lgb_device = \"gpu\" if has_gpu else \"cpu\"\n",
        "print(f\"🔧 Using LightGBM on {lgb_device.upper()}\")\n",
        "\n",
        "\n",
        "lgb_models = {t: [] for t in y_train.columns}\n",
        "val_mapes  = {}\n",
        "study_db   = optuna.storages.InMemoryStorage()\n",
        "\n",
        "def objective_factory(X, y):\n",
        "    def obj(trial):\n",
        "        params = {\n",
        "            \"objective\": \"rmse\",\n",
        "            \"metric\": \"mae\",\n",
        "            \"verbosity\": -1,\n",
        "            \"boosting_type\": \"gbdt\",\n",
        "            \"device\": lgb_device, # Use the determined device\n",
        "            \"learning_rate\": trial.suggest_float(\"lr\", 0.01, 0.2, log=True),\n",
        "            \"num_leaves\": trial.suggest_int(\"leaves\", 31, 1023, log=True),\n",
        "            \"feature_fraction\": trial.suggest_float(\"feat_frac\", 0.5, 1.0),\n",
        "            \"bagging_fraction\": trial.suggest_float(\"bag_frac\", 0.5, 1.0),\n",
        "            \"bagging_freq\": 1,\n",
        "            \"min_data_in_leaf\": trial.suggest_int(\"min_leaf\", 20, 200),\n",
        "            \"lambda_l1\": trial.suggest_float(\"l1\", 0.0, 5.0),\n",
        "            \"lambda_l2\": trial.suggest_float(\"l2\", 0.0, 5.0),\n",
        "            \"seed\": SEED,\n",
        "        }\n",
        "        mape_scores=[]\n",
        "        for tr, vl in gkf.split(X, y, groups):\n",
        "            # Explicitly provide feature names to lgb.Dataset\n",
        "            lgb_train = lgb.Dataset(X.iloc[tr], y.iloc[tr], feature_name=X.columns.tolist())\n",
        "            lgb_val   = lgb.Dataset(X.iloc[vl], y.iloc[vl], feature_name=X.columns.tolist())\n",
        "            m = lgb.train(params, lgb_train,\n",
        "                          num_boost_round=2000,\n",
        "                          valid_sets=[lgb_val],\n",
        "                          callbacks=[lgb.early_stopping(100, verbose=False)])\n",
        "            pr = m.predict(X.iloc[vl])\n",
        "            mape_scores.append(mean_absolute_percentage_error(y.iloc[vl], pr))\n",
        "        return np.mean(mape_scores)\n",
        "    return obj\n",
        "\n",
        "for tgt in y_train.columns:\n",
        "    print(f\"\\n🔎 Tuning LightGBM for {tgt} …\")\n",
        "    study = optuna.create_study(direction=\"minimize\", storage=study_db, sampler=optuna.samplers.TPESampler(seed=SEED))\n",
        "    # Replaced args.trials with OPTUNA_TRIALS\n",
        "    study.optimize(objective_factory(X_train, y_train[tgt]), n_trials=OPTUNA_TRIALS, show_progress_bar=False)\n",
        "    best = study.best_trial.params\n",
        "    best.update({\"objective\":\"rmse\",\"metric\":\"mae\",\"verbosity\":-1,\"device\":lgb_device,\"seed\":SEED})\n",
        "    fold_mapes=[]\n",
        "    for fold,(tr,vl) in enumerate(gkf.split(X_train, y_train[tgt], groups)):\n",
        "        # Explicitly provide feature names to lgb.Dataset for final training\n",
        "        mdl = lgb.train(best, lgb.Dataset(X_train.iloc[tr], y_train[tgt].iloc[tr], feature_name=X_train.columns.tolist()),\n",
        "                        num_boost_round=study.best_trial.user_attrs.get(\"best_iteration\", 1000))\n",
        "        lgb_models[tgt].append(mdl)\n",
        "        pr = mdl.predict(X_train.iloc[vl])\n",
        "        fold_mapes.append(mean_absolute_percentage_error(y_train[tgt].iloc[vl], pr))\n",
        "    val_mapes[tgt] = np.mean(fold_mapes)\n",
        "    print(f\"📊 {tgt} CV‑MAPE {val_mapes[tgt]:.4f}\")\n",
        "\n",
        "print(f\"\\n📈 Mean CV‑MAPE over all targets: {np.mean(list(val_mapes.values())):.4f}\")\n",
        "\n",
        "# 7. Predict on test with LightGBM models\n",
        "test_preds_lgb = pd.DataFrame({t: np.mean([m.predict(X_test) for m in mdl_list], axis=0) for t, mdl_list in lgb_models.items()})\n",
        "\n",
        "# 8. Build submission\n",
        "submission = test_preds_lgb.copy()\n",
        "submission.insert(0, \"ID\", test[\"ID\"])\n",
        "# Replaced args.out with SUBMISSION_FILE\n",
        "submission.to_csv(SUBMISSION_FILE, index=False)\n",
        "\n",
        "# Removed CatBoost training and blending for now\n",
        "# ------------------------------------------------------------------------------\n",
        "# 7. CatBoost quick model (no tuning, GPU if available)\n",
        "# ------------------------------------------------------------------------------\n",
        "# cat_models = {}\n",
        "# has_gpu = CatBoostRegressor().get_param(\"task_type\")==\"GPU\" if os.getenv(\"CUDA_VISIBLE_DEVICES\") else False\n",
        "# cat_params = dict(\n",
        "#     iterations=1200,\n",
        "#     depth=8,\n",
        "#     learning_rate=0.05,\n",
        "#     loss_function=\"MAE\",\n",
        "#     task_type=\"GPU\" if has_gpu else \"CPU\",\n",
        "#     verbose=False,\n",
        "#     random_seed=SEED,\n",
        "# )\n",
        "\n",
        "# print(f\"\\n🚂 Training CatBoost ({'GPU' if has_gpu else 'CPU'}) …\")\n",
        "# for tgt in y_train.columns:\n",
        "#     cat = CatBoostRegressor(**cat_params)\n",
        "#     cat.fit(X_train, y_train[tgt])\n",
        "#     cat_models[tgt] = cat\n",
        "\n",
        "# # ------------------------------------------------------------------------------\n",
        "# # 8. Predict & blend\n",
        "# # ------------------------------------------------------------------------------\n",
        "# preds_lgb = {}\n",
        "# for tgt, mdl_list in lgb_models.items():\n",
        "#     fold_preds = np.mean([m.predict(X_test) for m in mdl_list], axis=0)\n",
        "#     preds_lgb[tgt] = fold_preds\n",
        "\n",
        "# preds_cat = {tgt: mdl.predict(X_test) for tgt, mdl in cat_models.items()}\n",
        "\n",
        "# alpha = args.lgb_weight # This will cause NameError now\n",
        "# blend_preds = {tgt: alpha*preds_lgb[tgt] + (1-alpha)*preds_cat[tgt] for tgt in y_train.columns}\n",
        "\n",
        "# submission = pd.DataFrame(blend_preds)\n",
        "# submission.insert(0, \"ID\", test[\"ID\"])\n",
        "# submission.to_csv(args.out, index=False) # This will cause NameError now\n",
        "\n",
        "\n",
        "print(f\"\\n✅ Submission saved to “{SUBMISSION_FILE}”\")\n",
        "# Removed the line about uploading to leaderboard as it's a partial script now\n",
        "# print(\"    You can now upload it to the leaderboard.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PZ8077bwxWyg",
        "outputId": "7a1da5e8-282a-4994-ee8f-3c7c2a9e12ed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-07 10:51:37,737] A new study created in memory with name: no-name-ef687e2b-f121-4e83-b282-dc2406603877\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 Using LightGBM on CPU\n",
            "\n",
            "🔎 Tuning LightGBM for BlendProperty1 …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-07 10:52:25,077] Trial 0 finished with value: 2.9762621204236153 and parameters: {'lr': 0.030710573677773714, 'leaves': 861, 'feat_frac': 0.8659969709057025, 'bag_frac': 0.7993292420985183, 'min_leaf': 48, 'l1': 0.7799726016810132, 'l2': 0.2904180608409973}. Best is trial 0 with value: 2.9762621204236153.\n",
            "[I 2025-07-07 10:52:31,537] Trial 1 finished with value: 10.274782004593735 and parameters: {'lr': 0.13394334706750485, 'leaves': 252, 'feat_frac': 0.8540362888980227, 'bag_frac': 0.5102922471479012, 'min_leaf': 195, 'l1': 4.162213204002109, 'l2': 1.0616955533913808}. Best is trial 0 with value: 2.9762621204236153.\n",
            "[I 2025-07-07 10:53:00,915] Trial 2 finished with value: 2.094722361703428 and parameters: {'lr': 0.017240892195821537, 'leaves': 58, 'feat_frac': 0.6521211214797689, 'bag_frac': 0.762378215816119, 'min_leaf': 98, 'l1': 1.4561457009902097, 'l2': 3.0592644736118975}. Best is trial 2 with value: 2.094722361703428.\n",
            "[I 2025-07-07 10:53:19,502] Trial 3 finished with value: 3.9046302079667456 and parameters: {'lr': 0.01518747922672247, 'leaves': 85, 'feat_frac': 0.6831809216468459, 'bag_frac': 0.728034992108518, 'min_leaf': 162, 'l1': 0.9983689107917987, 'l2': 2.571172192068058}. Best is trial 2 with value: 2.094722361703428.\n",
            "[I 2025-07-07 10:53:33,197] Trial 4 finished with value: 1.5126891974723198 and parameters: {'lr': 0.05898602410432694, 'leaves': 36, 'feat_frac': 0.8037724259507192, 'bag_frac': 0.5852620618436457, 'min_leaf': 31, 'l1': 4.7444276862666666, 'l2': 4.828160165372797}. Best is trial 4 with value: 1.5126891974723198.\n",
            "[I 2025-07-07 10:53:41,209] Trial 5 finished with value: 2.128814313452463 and parameters: {'lr': 0.11265466963346032, 'leaves': 89, 'feat_frac': 0.5488360570031919, 'bag_frac': 0.8421165132560784, 'min_leaf': 99, 'l1': 0.6101911742238941, 'l2': 2.475884550556351}. Best is trial 4 with value: 1.5126891974723198.\n",
            "[I 2025-07-07 10:54:12,312] Trial 6 finished with value: 1.81719477859452 and parameters: {'lr': 0.011085122517311707, 'leaves': 744, 'feat_frac': 0.6293899908000085, 'bag_frac': 0.831261142176991, 'min_leaf': 76, 'l1': 2.600340105889054, 'l2': 2.7335513967163982}. Best is trial 4 with value: 1.5126891974723198.\n",
            "[I 2025-07-07 10:54:40,098] Trial 7 finished with value: 1.720048435595865 and parameters: {'lr': 0.017398074711291726, 'leaves': 920, 'feat_frac': 0.8875664116805573, 'bag_frac': 0.9697494707820946, 'min_leaf': 181, 'l1': 2.9894998940554256, 'l2': 4.609371175115584}. Best is trial 4 with value: 1.5126891974723198.\n",
            "[I 2025-07-07 10:55:02,361] Trial 8 finished with value: 1.0717156447745526 and parameters: {'lr': 0.01303561122512888, 'leaves': 61, 'feat_frac': 0.522613644455269, 'bag_frac': 0.6626651653816322, 'min_leaf': 90, 'l1': 1.3567451588694794, 'l2': 4.143687545759647}. Best is trial 8 with value: 1.0717156447745526.\n",
            "[I 2025-07-07 10:55:16,660] Trial 9 finished with value: 4.604387961458554 and parameters: {'lr': 0.02911701023242742, 'leaves': 82, 'feat_frac': 0.7713480415791243, 'bag_frac': 0.5704621124873813, 'min_leaf': 165, 'l1': 0.3727532183988541, 'l2': 4.9344346830025865}. Best is trial 8 with value: 1.0717156447745526.\n",
            "[I 2025-07-07 10:55:33,377] Trial 10 finished with value: 3.7127965405718633 and parameters: {'lr': 0.046589863196059025, 'leaves': 216, 'feat_frac': 0.9847685553939328, 'bag_frac': 0.6734254457033109, 'min_leaf': 135, 'l1': 1.9014648012590527, 'l2': 3.6518344760350483}. Best is trial 8 with value: 1.0717156447745526.\n",
            "[I 2025-07-07 10:55:46,160] Trial 11 finished with value: 1.4317123665409468 and parameters: {'lr': 0.06761147179060022, 'leaves': 33, 'feat_frac': 0.5033905463786833, 'bag_frac': 0.640380477119852, 'min_leaf': 21, 'l1': 4.623808979969583, 'l2': 4.262787055401152}. Best is trial 8 with value: 1.0717156447745526.\n",
            "[I 2025-07-07 10:55:54,330] Trial 12 finished with value: 1.8894532525370564 and parameters: {'lr': 0.07297448422270648, 'leaves': 32, 'feat_frac': 0.5054061811566842, 'bag_frac': 0.6531662960138486, 'min_leaf': 59, 'l1': 3.718902550289007, 'l2': 3.808261843772377}. Best is trial 8 with value: 1.0717156447745526.\n",
            "[I 2025-07-07 10:55:58,735] Trial 13 finished with value: 3.9152849466795594 and parameters: {'lr': 0.19198491507424617, 'leaves': 50, 'feat_frac': 0.5778169141864935, 'bag_frac': 0.6335302704290142, 'min_leaf': 26, 'l1': 1.9069227332359433, 'l2': 4.183849497741762}. Best is trial 8 with value: 1.0717156447745526.\n",
            "[I 2025-07-07 10:56:11,610] Trial 14 finished with value: 2.373713605557963 and parameters: {'lr': 0.028657298114346672, 'leaves': 138, 'feat_frac': 0.5009218901173191, 'bag_frac': 0.7084623041637502, 'min_leaf': 126, 'l1': 3.3170321430599126, 'l2': 1.6143598559125798}. Best is trial 8 with value: 1.0717156447745526.\n",
            "[I 2025-07-07 10:56:21,710] Trial 15 finished with value: 2.848641793186029 and parameters: {'lr': 0.08102305609389716, 'leaves': 396, 'feat_frac': 0.7030710865753411, 'bag_frac': 0.9106491574992951, 'min_leaf': 75, 'l1': 4.995036367847375, 'l2': 3.482363725774687}. Best is trial 8 with value: 1.0717156447745526.\n",
            "[I 2025-07-07 10:56:34,791] Trial 16 finished with value: 1.8887873238989905 and parameters: {'lr': 0.04021015091476339, 'leaves': 48, 'feat_frac': 0.5938669522491125, 'bag_frac': 0.5943855620860092, 'min_leaf': 123, 'l1': 0.02641488392022051, 'l2': 4.232473894709022}. Best is trial 8 with value: 1.0717156447745526.\n",
            "[I 2025-07-07 10:56:41,691] Trial 17 finished with value: 4.186435023375745 and parameters: {'lr': 0.1037898068626402, 'leaves': 129, 'feat_frac': 0.546582455285404, 'bag_frac': 0.5056601521163473, 'min_leaf': 48, 'l1': 2.1709671578847196, 'l2': 1.960315080537601}. Best is trial 8 with value: 1.0717156447745526.\n",
            "[I 2025-07-07 10:57:34,291] Trial 18 finished with value: 2.2814483066344056 and parameters: {'lr': 0.010567888966433129, 'leaves': 31, 'feat_frac': 0.7189017147104544, 'bag_frac': 0.6835678996789387, 'min_leaf': 20, 'l1': 1.4070712978947963, 'l2': 3.246045332055195}. Best is trial 8 with value: 1.0717156447745526.\n",
            "[I 2025-07-07 10:57:49,936] Trial 19 finished with value: 1.0679584255312802 and parameters: {'lr': 0.022782004381045613, 'leaves': 67, 'feat_frac': 0.6224633116883797, 'bag_frac': 0.7550429827211348, 'min_leaf': 86, 'l1': 4.174689687391343, 'l2': 4.1769002088598}. Best is trial 19 with value: 1.0679584255312802.\n",
            "[I 2025-07-07 10:59:01,590] A new study created in memory with name: no-name-42b00740-d786-4d80-82eb-a3459fa6c080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 BlendProperty1 CV‑MAPE 4.9971\n",
            "\n",
            "🔎 Tuning LightGBM for BlendProperty2 …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-07 10:59:39,289] Trial 0 finished with value: 0.8720265634177714 and parameters: {'lr': 0.030710573677773714, 'leaves': 861, 'feat_frac': 0.8659969709057025, 'bag_frac': 0.7993292420985183, 'min_leaf': 48, 'l1': 0.7799726016810132, 'l2': 0.2904180608409973}. Best is trial 0 with value: 0.8720265634177714.\n",
            "[I 2025-07-07 10:59:47,256] Trial 1 finished with value: 1.5292228343097805 and parameters: {'lr': 0.13394334706750485, 'leaves': 252, 'feat_frac': 0.8540362888980227, 'bag_frac': 0.5102922471479012, 'min_leaf': 195, 'l1': 4.162213204002109, 'l2': 1.0616955533913808}. Best is trial 0 with value: 0.8720265634177714.\n",
            "[I 2025-07-07 11:00:14,705] Trial 2 finished with value: 0.8993345602565732 and parameters: {'lr': 0.017240892195821537, 'leaves': 58, 'feat_frac': 0.6521211214797689, 'bag_frac': 0.762378215816119, 'min_leaf': 98, 'l1': 1.4561457009902097, 'l2': 3.0592644736118975}. Best is trial 0 with value: 0.8720265634177714.\n",
            "[I 2025-07-07 11:00:35,480] Trial 3 finished with value: 1.3393669189302482 and parameters: {'lr': 0.01518747922672247, 'leaves': 85, 'feat_frac': 0.6831809216468459, 'bag_frac': 0.728034992108518, 'min_leaf': 162, 'l1': 0.9983689107917987, 'l2': 2.571172192068058}. Best is trial 0 with value: 0.8720265634177714.\n",
            "[I 2025-07-07 11:00:48,916] Trial 4 finished with value: 0.9566741906797462 and parameters: {'lr': 0.05898602410432694, 'leaves': 36, 'feat_frac': 0.8037724259507192, 'bag_frac': 0.5852620618436457, 'min_leaf': 31, 'l1': 4.7444276862666666, 'l2': 4.828160165372797}. Best is trial 0 with value: 0.8720265634177714.\n",
            "[I 2025-07-07 11:00:54,584] Trial 5 finished with value: 1.1263701980900502 and parameters: {'lr': 0.11265466963346032, 'leaves': 89, 'feat_frac': 0.5488360570031919, 'bag_frac': 0.8421165132560784, 'min_leaf': 99, 'l1': 0.6101911742238941, 'l2': 2.475884550556351}. Best is trial 0 with value: 0.8720265634177714.\n",
            "[I 2025-07-07 11:01:25,231] Trial 6 finished with value: 0.946372241316749 and parameters: {'lr': 0.011085122517311707, 'leaves': 744, 'feat_frac': 0.6293899908000085, 'bag_frac': 0.831261142176991, 'min_leaf': 76, 'l1': 2.600340105889054, 'l2': 2.7335513967163982}. Best is trial 0 with value: 0.8720265634177714.\n",
            "[I 2025-07-07 11:01:52,963] Trial 7 finished with value: 1.2892701227627017 and parameters: {'lr': 0.017398074711291726, 'leaves': 920, 'feat_frac': 0.8875664116805573, 'bag_frac': 0.9697494707820946, 'min_leaf': 181, 'l1': 2.9894998940554256, 'l2': 4.609371175115584}. Best is trial 0 with value: 0.8720265634177714.\n",
            "[I 2025-07-07 11:02:15,188] Trial 8 finished with value: 0.9179792724271193 and parameters: {'lr': 0.01303561122512888, 'leaves': 61, 'feat_frac': 0.522613644455269, 'bag_frac': 0.6626651653816322, 'min_leaf': 90, 'l1': 1.3567451588694794, 'l2': 4.143687545759647}. Best is trial 0 with value: 0.8720265634177714.\n",
            "[I 2025-07-07 11:02:33,745] Trial 9 finished with value: 1.4171257169438056 and parameters: {'lr': 0.02911701023242742, 'leaves': 82, 'feat_frac': 0.7713480415791243, 'bag_frac': 0.5704621124873813, 'min_leaf': 165, 'l1': 0.3727532183988541, 'l2': 4.9344346830025865}. Best is trial 0 with value: 0.8720265634177714.\n",
            "[I 2025-07-07 11:02:56,398] Trial 10 finished with value: 1.216170002174058 and parameters: {'lr': 0.046589863196059025, 'leaves': 365, 'feat_frac': 0.9847685553939328, 'bag_frac': 0.9661451709558936, 'min_leaf': 22, 'l1': 1.9902167111008833, 'l2': 0.0757211855137842}. Best is trial 0 with value: 0.8720265634177714.\n",
            "[I 2025-07-07 11:03:23,527] Trial 11 finished with value: 0.9851649620484144 and parameters: {'lr': 0.026503493101071127, 'leaves': 173, 'feat_frac': 0.6757643662651726, 'bag_frac': 0.8176289079288437, 'min_leaf': 56, 'l1': 1.7142490820380103, 'l2': 1.4611923275099303}. Best is trial 0 with value: 0.8720265634177714.\n",
            "[I 2025-07-07 11:03:47,113] Trial 12 finished with value: 1.092367701460292 and parameters: {'lr': 0.027885091538984885, 'leaves': 474, 'feat_frac': 0.9490222375504709, 'bag_frac': 0.7429199649566068, 'min_leaf': 121, 'l1': 0.05789471896006004, 'l2': 3.679172819887455}. Best is trial 0 with value: 0.8720265634177714.\n",
            "[I 2025-07-07 11:03:58,076] Trial 13 finished with value: 1.031681417927415 and parameters: {'lr': 0.07890559538527207, 'leaves': 158, 'feat_frac': 0.737377247848091, 'bag_frac': 0.8859620061900355, 'min_leaf': 135, 'l1': 2.249424948447833, 'l2': 3.369320744702511}. Best is trial 0 with value: 0.8720265634177714.\n",
            "[I 2025-07-07 11:04:17,751] Trial 14 finished with value: 0.9320520828468798 and parameters: {'lr': 0.021463291373421976, 'leaves': 33, 'feat_frac': 0.6202030659902121, 'bag_frac': 0.6780878735259952, 'min_leaf': 58, 'l1': 3.3170321430599126, 'l2': 1.6045670126775096}. Best is trial 0 with value: 0.8720265634177714.\n",
            "[I 2025-07-07 11:04:43,988] Trial 15 finished with value: 1.0323704743229944 and parameters: {'lr': 0.0398383677528818, 'leaves': 444, 'feat_frac': 0.8833782585487949, 'bag_frac': 0.8994218541235229, 'min_leaf': 55, 'l1': 1.047042468330117, 'l2': 0.17007587054064904}. Best is trial 0 with value: 0.8720265634177714.\n",
            "[I 2025-07-07 11:05:00,576] Trial 16 finished with value: 1.0613277415508666 and parameters: {'lr': 0.03966680020441264, 'leaves': 124, 'feat_frac': 0.7261631564388041, 'bag_frac': 0.7804241154696392, 'min_leaf': 126, 'l1': 1.594737073120609, 'l2': 0.7689596058375276}. Best is trial 0 with value: 0.8720265634177714.\n",
            "[I 2025-07-07 11:05:31,930] Trial 17 finished with value: 0.8980511557196417 and parameters: {'lr': 0.019425536794910853, 'leaves': 54, 'feat_frac': 0.8086345643897362, 'bag_frac': 0.6653474575296436, 'min_leaf': 79, 'l1': 1.0040777552514473, 'l2': 1.975516806898474}. Best is trial 0 with value: 0.8720265634177714.\n",
            "[I 2025-07-07 11:06:34,883] Trial 18 finished with value: 0.9132214994899582 and parameters: {'lr': 0.01003053874920411, 'leaves': 275, 'feat_frac': 0.8302996229142291, 'bag_frac': 0.6613871750096798, 'min_leaf': 40, 'l1': 0.5176784047921146, 'l2': 1.8291868579730854}. Best is trial 0 with value: 0.8720265634177714.\n",
            "[I 2025-07-07 11:06:45,907] Trial 19 finished with value: 1.0099356946361202 and parameters: {'lr': 0.07436902054944462, 'leaves': 650, 'feat_frac': 0.9344585828141339, 'bag_frac': 0.6008964335081206, 'min_leaf': 76, 'l1': 0.8532132291804775, 'l2': 2.0604832619703526}. Best is trial 0 with value: 0.8720265634177714.\n",
            "[I 2025-07-07 11:07:59,229] A new study created in memory with name: no-name-0bb4adfb-7674-497e-80ca-6f7276acc388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 BlendProperty2 CV‑MAPE 1.0287\n",
            "\n",
            "🔎 Tuning LightGBM for BlendProperty3 …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-07 11:08:27,377] Trial 0 finished with value: 1.1183469754657156 and parameters: {'lr': 0.030710573677773714, 'leaves': 861, 'feat_frac': 0.8659969709057025, 'bag_frac': 0.7993292420985183, 'min_leaf': 48, 'l1': 0.7799726016810132, 'l2': 0.2904180608409973}. Best is trial 0 with value: 1.1183469754657156.\n",
            "[I 2025-07-07 11:08:30,565] Trial 1 finished with value: 1.7274834783625383 and parameters: {'lr': 0.13394334706750485, 'leaves': 252, 'feat_frac': 0.8540362888980227, 'bag_frac': 0.5102922471479012, 'min_leaf': 195, 'l1': 4.162213204002109, 'l2': 1.0616955533913808}. Best is trial 0 with value: 1.1183469754657156.\n",
            "[I 2025-07-07 11:08:56,108] Trial 2 finished with value: 1.206814450721291 and parameters: {'lr': 0.017240892195821537, 'leaves': 58, 'feat_frac': 0.6521211214797689, 'bag_frac': 0.762378215816119, 'min_leaf': 98, 'l1': 1.4561457009902097, 'l2': 3.0592644736118975}. Best is trial 0 with value: 1.1183469754657156.\n",
            "[I 2025-07-07 11:09:17,959] Trial 3 finished with value: 1.3737671630517825 and parameters: {'lr': 0.01518747922672247, 'leaves': 85, 'feat_frac': 0.6831809216468459, 'bag_frac': 0.728034992108518, 'min_leaf': 162, 'l1': 0.9983689107917987, 'l2': 2.571172192068058}. Best is trial 0 with value: 1.1183469754657156.\n",
            "[I 2025-07-07 11:09:29,221] Trial 4 finished with value: 1.2330057066763742 and parameters: {'lr': 0.05898602410432694, 'leaves': 36, 'feat_frac': 0.8037724259507192, 'bag_frac': 0.5852620618436457, 'min_leaf': 31, 'l1': 4.7444276862666666, 'l2': 4.828160165372797}. Best is trial 0 with value: 1.1183469754657156.\n",
            "[I 2025-07-07 11:09:34,624] Trial 5 finished with value: 1.1371075496299088 and parameters: {'lr': 0.11265466963346032, 'leaves': 89, 'feat_frac': 0.5488360570031919, 'bag_frac': 0.8421165132560784, 'min_leaf': 99, 'l1': 0.6101911742238941, 'l2': 2.475884550556351}. Best is trial 0 with value: 1.1183469754657156.\n",
            "[I 2025-07-07 11:10:05,981] Trial 6 finished with value: 1.2680423407981716 and parameters: {'lr': 0.011085122517311707, 'leaves': 744, 'feat_frac': 0.6293899908000085, 'bag_frac': 0.831261142176991, 'min_leaf': 76, 'l1': 2.600340105889054, 'l2': 2.7335513967163982}. Best is trial 0 with value: 1.1183469754657156.\n",
            "[I 2025-07-07 11:10:33,795] Trial 7 finished with value: 1.2422422215819067 and parameters: {'lr': 0.017398074711291726, 'leaves': 920, 'feat_frac': 0.8875664116805573, 'bag_frac': 0.9697494707820946, 'min_leaf': 181, 'l1': 2.9894998940554256, 'l2': 4.609371175115584}. Best is trial 0 with value: 1.1183469754657156.\n",
            "[I 2025-07-07 11:10:55,726] Trial 8 finished with value: 1.2081815996248562 and parameters: {'lr': 0.01303561122512888, 'leaves': 61, 'feat_frac': 0.522613644455269, 'bag_frac': 0.6626651653816322, 'min_leaf': 90, 'l1': 1.3567451588694794, 'l2': 4.143687545759647}. Best is trial 0 with value: 1.1183469754657156.\n",
            "[I 2025-07-07 11:11:08,817] Trial 9 finished with value: 1.5290761575856355 and parameters: {'lr': 0.02911701023242742, 'leaves': 82, 'feat_frac': 0.7713480415791243, 'bag_frac': 0.5704621124873813, 'min_leaf': 165, 'l1': 0.3727532183988541, 'l2': 4.9344346830025865}. Best is trial 0 with value: 1.1183469754657156.\n",
            "[I 2025-07-07 11:11:24,653] Trial 10 finished with value: 1.0636924891685375 and parameters: {'lr': 0.046589863196059025, 'leaves': 365, 'feat_frac': 0.9847685553939328, 'bag_frac': 0.9661451709558936, 'min_leaf': 22, 'l1': 1.9902167111008833, 'l2': 0.0757211855137842}. Best is trial 10 with value: 1.0636924891685375.\n",
            "[I 2025-07-07 11:11:37,072] Trial 11 finished with value: 1.1147406879021822 and parameters: {'lr': 0.042987099962655866, 'leaves': 391, 'feat_frac': 0.9987827539727656, 'bag_frac': 0.9968676185612808, 'min_leaf': 21, 'l1': 2.07495575856821, 'l2': 0.14281808621478395}. Best is trial 10 with value: 1.0636924891685375.\n",
            "[I 2025-07-07 11:11:46,352] Trial 12 finished with value: 1.0422905196586743 and parameters: {'lr': 0.06698266383768514, 'leaves': 359, 'feat_frac': 0.9976068260035007, 'bag_frac': 0.9995004182654049, 'min_leaf': 21, 'l1': 1.9379710203198037, 'l2': 0.2250830848923579}. Best is trial 12 with value: 1.0422905196586743.\n",
            "[I 2025-07-07 11:11:57,070] Trial 13 finished with value: 0.9981593018343344 and parameters: {'lr': 0.07890559538527207, 'leaves': 390, 'feat_frac': 0.978823001102528, 'bag_frac': 0.9310662972969539, 'min_leaf': 63, 'l1': 2.018398472270893, 'l2': 1.1356950582543923}. Best is trial 13 with value: 0.9981593018343344.\n",
            "[I 2025-07-07 11:12:09,823] Trial 14 finished with value: 1.2632526641849113 and parameters: {'lr': 0.07030578918551263, 'leaves': 172, 'feat_frac': 0.9358515504377549, 'bag_frac': 0.9159468880389681, 'min_leaf': 60, 'l1': 3.3170321430599126, 'l2': 1.2143761097343941}. Best is trial 13 with value: 0.9981593018343344.\n",
            "[I 2025-07-07 11:12:14,319] Trial 15 finished with value: 1.4661496725546503 and parameters: {'lr': 0.19765072745196458, 'leaves': 396, 'feat_frac': 0.9294916958907002, 'bag_frac': 0.8983719382835197, 'min_leaf': 55, 'l1': 1.912417448097673, 'l2': 1.2861914281797506}. Best is trial 13 with value: 0.9981593018343344.\n",
            "[I 2025-07-07 11:12:26,630] Trial 16 finished with value: 1.2244660537661685 and parameters: {'lr': 0.09093736516039114, 'leaves': 172, 'feat_frac': 0.9460296826818366, 'bag_frac': 0.897486563300622, 'min_leaf': 130, 'l1': 0.05181246513515547, 'l2': 1.8698885287079219}. Best is trial 13 with value: 0.9981593018343344.\n",
            "[I 2025-07-07 11:12:36,200] Trial 17 finished with value: 1.39220247393867 and parameters: {'lr': 0.07989185820680454, 'leaves': 533, 'feat_frac': 0.7320832480224756, 'bag_frac': 0.9304701421384158, 'min_leaf': 125, 'l1': 3.5516426234676324, 'l2': 0.7190004434253967}. Best is trial 13 with value: 0.9981593018343344.\n",
            "[I 2025-07-07 11:12:43,982] Trial 18 finished with value: 1.1869045559186988 and parameters: {'lr': 0.16640556451022465, 'leaves': 275, 'feat_frac': 0.8176102269546232, 'bag_frac': 0.8654184916550071, 'min_leaf': 42, 'l1': 2.6916233039904482, 'l2': 1.7919514239527086}. Best is trial 13 with value: 0.9981593018343344.\n",
            "[I 2025-07-07 11:12:58,965] Trial 19 finished with value: 1.2495930607838868 and parameters: {'lr': 0.05248156245045793, 'leaves': 533, 'feat_frac': 0.8991630668768816, 'bag_frac': 0.7101511979950793, 'min_leaf': 66, 'l1': 1.580096457131237, 'l2': 0.6590114693263953}. Best is trial 13 with value: 0.9981593018343344.\n",
            "[I 2025-07-07 11:14:11,867] A new study created in memory with name: no-name-ca63fd4b-640d-492f-86a2-0e2259114fd4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 BlendProperty3 CV‑MAPE 1.1003\n",
            "\n",
            "🔎 Tuning LightGBM for BlendProperty4 …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-07 11:14:43,847] Trial 0 finished with value: 0.857333884537123 and parameters: {'lr': 0.030710573677773714, 'leaves': 861, 'feat_frac': 0.8659969709057025, 'bag_frac': 0.7993292420985183, 'min_leaf': 48, 'l1': 0.7799726016810132, 'l2': 0.2904180608409973}. Best is trial 0 with value: 0.857333884537123.\n",
            "[I 2025-07-07 11:14:49,838] Trial 1 finished with value: 1.82387008987217 and parameters: {'lr': 0.13394334706750485, 'leaves': 252, 'feat_frac': 0.8540362888980227, 'bag_frac': 0.5102922471479012, 'min_leaf': 195, 'l1': 4.162213204002109, 'l2': 1.0616955533913808}. Best is trial 0 with value: 0.857333884537123.\n",
            "[I 2025-07-07 11:15:14,302] Trial 2 finished with value: 1.0373612934206258 and parameters: {'lr': 0.017240892195821537, 'leaves': 58, 'feat_frac': 0.6521211214797689, 'bag_frac': 0.762378215816119, 'min_leaf': 98, 'l1': 1.4561457009902097, 'l2': 3.0592644736118975}. Best is trial 0 with value: 0.857333884537123.\n",
            "[I 2025-07-07 11:15:35,272] Trial 3 finished with value: 1.5842139948727927 and parameters: {'lr': 0.01518747922672247, 'leaves': 85, 'feat_frac': 0.6831809216468459, 'bag_frac': 0.728034992108518, 'min_leaf': 162, 'l1': 0.9983689107917987, 'l2': 2.571172192068058}. Best is trial 0 with value: 0.857333884537123.\n",
            "[I 2025-07-07 11:15:47,827] Trial 4 finished with value: 0.9564838943104503 and parameters: {'lr': 0.05898602410432694, 'leaves': 36, 'feat_frac': 0.8037724259507192, 'bag_frac': 0.5852620618436457, 'min_leaf': 31, 'l1': 4.7444276862666666, 'l2': 4.828160165372797}. Best is trial 0 with value: 0.857333884537123.\n",
            "[I 2025-07-07 11:15:53,160] Trial 5 finished with value: 1.172852488347737 and parameters: {'lr': 0.11265466963346032, 'leaves': 89, 'feat_frac': 0.5488360570031919, 'bag_frac': 0.8421165132560784, 'min_leaf': 99, 'l1': 0.6101911742238941, 'l2': 2.475884550556351}. Best is trial 0 with value: 0.857333884537123.\n",
            "[I 2025-07-07 11:16:26,912] Trial 6 finished with value: 0.9706562921964281 and parameters: {'lr': 0.011085122517311707, 'leaves': 744, 'feat_frac': 0.6293899908000085, 'bag_frac': 0.831261142176991, 'min_leaf': 76, 'l1': 2.600340105889054, 'l2': 2.7335513967163982}. Best is trial 0 with value: 0.857333884537123.\n",
            "[I 2025-07-07 11:16:55,582] Trial 7 finished with value: 1.4880265457441832 and parameters: {'lr': 0.017398074711291726, 'leaves': 920, 'feat_frac': 0.8875664116805573, 'bag_frac': 0.9697494707820946, 'min_leaf': 181, 'l1': 2.9894998940554256, 'l2': 4.609371175115584}. Best is trial 0 with value: 0.857333884537123.\n",
            "[I 2025-07-07 11:17:18,222] Trial 8 finished with value: 1.0991004403355114 and parameters: {'lr': 0.01303561122512888, 'leaves': 61, 'feat_frac': 0.522613644455269, 'bag_frac': 0.6626651653816322, 'min_leaf': 90, 'l1': 1.3567451588694794, 'l2': 4.143687545759647}. Best is trial 0 with value: 0.857333884537123.\n",
            "[I 2025-07-07 11:17:32,058] Trial 9 finished with value: 1.70846071007234 and parameters: {'lr': 0.02911701023242742, 'leaves': 82, 'feat_frac': 0.7713480415791243, 'bag_frac': 0.5704621124873813, 'min_leaf': 165, 'l1': 0.3727532183988541, 'l2': 4.9344346830025865}. Best is trial 0 with value: 0.857333884537123.\n",
            "[I 2025-07-07 11:17:53,109] Trial 10 finished with value: 1.0030745398142433 and parameters: {'lr': 0.046589863196059025, 'leaves': 365, 'feat_frac': 0.9847685553939328, 'bag_frac': 0.9661451709558936, 'min_leaf': 22, 'l1': 1.9902167111008833, 'l2': 0.0757211855137842}. Best is trial 0 with value: 0.857333884537123.\n",
            "[I 2025-07-07 11:18:05,096] Trial 11 finished with value: 1.0442638171262588 and parameters: {'lr': 0.061284494551261066, 'leaves': 173, 'feat_frac': 0.8218563683119118, 'bag_frac': 0.6384415889770061, 'min_leaf': 21, 'l1': 4.764371043871234, 'l2': 1.2736128523556052}. Best is trial 0 with value: 0.857333884537123.\n",
            "[I 2025-07-07 11:18:17,398] Trial 12 finished with value: 0.8336044667670294 and parameters: {'lr': 0.07859632132013526, 'leaves': 33, 'feat_frac': 0.9459003517271036, 'bag_frac': 0.8207606374385142, 'min_leaf': 56, 'l1': 3.394740324492875, 'l2': 3.7411361457960837}. Best is trial 12 with value: 0.8336044667670294.\n",
            "[I 2025-07-07 11:18:40,947] Trial 13 finished with value: 0.9347204172612786 and parameters: {'lr': 0.03141165532154899, 'leaves': 486, 'feat_frac': 0.9643494586779606, 'bag_frac': 0.8646837765045434, 'min_leaf': 59, 'l1': 3.433851762237047, 'l2': 3.5598890110670576}. Best is trial 12 with value: 0.8336044667670294.\n",
            "[I 2025-07-07 11:18:45,317] Trial 14 finished with value: 1.2817146597694715 and parameters: {'lr': 0.1816444498193539, 'leaves': 152, 'feat_frac': 0.9215983187957236, 'bag_frac': 0.7651857298716025, 'min_leaf': 132, 'l1': 3.6703254043501943, 'l2': 1.6045670126775096}. Best is trial 12 with value: 0.8336044667670294.\n",
            "[I 2025-07-07 11:18:55,157] Trial 15 finished with value: 0.8341752704187229 and parameters: {'lr': 0.09035555502757847, 'leaves': 32, 'feat_frac': 0.9193110694067963, 'bag_frac': 0.9040330172235821, 'min_leaf': 55, 'l1': 2.0670704984635635, 'l2': 0.17007587054064904}. Best is trial 12 with value: 0.8336044667670294.\n",
            "[I 2025-07-07 11:19:05,115] Trial 16 finished with value: 1.040545934403509 and parameters: {'lr': 0.0849923708435775, 'leaves': 39, 'feat_frac': 0.9377737096938104, 'bag_frac': 0.906795683013346, 'min_leaf': 126, 'l1': 2.166611533600529, 'l2': 3.7711555674031403}. Best is trial 12 with value: 0.8336044667670294.\n",
            "[I 2025-07-07 11:19:12,159] Trial 17 finished with value: 1.0862996120949118 and parameters: {'lr': 0.08975472404048251, 'leaves': 35, 'feat_frac': 0.7320832480224756, 'bag_frac': 0.913217399679865, 'min_leaf': 63, 'l1': 3.0537592039747157, 'l2': 2.0850736746159964}. Best is trial 12 with value: 0.8336044667670294.\n",
            "[I 2025-07-07 11:19:18,833] Trial 18 finished with value: 1.0564203456402739 and parameters: {'lr': 0.18662285506369958, 'leaves': 53, 'feat_frac': 0.920268595864156, 'bag_frac': 0.8893207305073152, 'min_leaf': 45, 'l1': 3.9011838649838184, 'l2': 3.332678196538594}. Best is trial 12 with value: 0.8336044667670294.\n",
            "[I 2025-07-07 11:19:31,295] Trial 19 finished with value: 0.954743277589405 and parameters: {'lr': 0.07436902054944462, 'leaves': 31, 'feat_frac': 0.97722889842474, 'bag_frac': 0.7226058560347508, 'min_leaf': 76, 'l1': 1.9009136319305533, 'l2': 0.6050961156932488}. Best is trial 12 with value: 0.8336044667670294.\n",
            "[I 2025-07-07 11:20:46,753] A new study created in memory with name: no-name-f24a0814-2ef5-4e62-961a-efce7b962eee\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 BlendProperty4 CV‑MAPE 0.8819\n",
            "\n",
            "🔎 Tuning LightGBM for BlendProperty5 …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-07 11:20:55,334] Trial 0 finished with value: 0.284902134047217 and parameters: {'lr': 0.030710573677773714, 'leaves': 861, 'feat_frac': 0.8659969709057025, 'bag_frac': 0.7993292420985183, 'min_leaf': 48, 'l1': 0.7799726016810132, 'l2': 0.2904180608409973}. Best is trial 0 with value: 0.284902134047217.\n",
            "[I 2025-07-07 11:20:57,988] Trial 1 finished with value: 2.1969521424358307 and parameters: {'lr': 0.13394334706750485, 'leaves': 252, 'feat_frac': 0.8540362888980227, 'bag_frac': 0.5102922471479012, 'min_leaf': 195, 'l1': 4.162213204002109, 'l2': 1.0616955533913808}. Best is trial 0 with value: 0.284902134047217.\n",
            "[I 2025-07-07 11:21:04,193] Trial 2 finished with value: 0.482054540505682 and parameters: {'lr': 0.017240892195821537, 'leaves': 58, 'feat_frac': 0.6521211214797689, 'bag_frac': 0.762378215816119, 'min_leaf': 98, 'l1': 1.4561457009902097, 'l2': 3.0592644736118975}. Best is trial 0 with value: 0.284902134047217.\n",
            "[I 2025-07-07 11:21:14,667] Trial 3 finished with value: 0.7197066882746087 and parameters: {'lr': 0.01518747922672247, 'leaves': 85, 'feat_frac': 0.6831809216468459, 'bag_frac': 0.728034992108518, 'min_leaf': 162, 'l1': 0.9983689107917987, 'l2': 2.571172192068058}. Best is trial 0 with value: 0.284902134047217.\n",
            "[I 2025-07-07 11:21:16,879] Trial 4 finished with value: 0.3986146292766885 and parameters: {'lr': 0.05898602410432694, 'leaves': 36, 'feat_frac': 0.8037724259507192, 'bag_frac': 0.5852620618436457, 'min_leaf': 31, 'l1': 4.7444276862666666, 'l2': 4.828160165372797}. Best is trial 0 with value: 0.284902134047217.\n",
            "[I 2025-07-07 11:21:21,153] Trial 5 finished with value: 0.5032928439515209 and parameters: {'lr': 0.11265466963346032, 'leaves': 89, 'feat_frac': 0.5488360570031919, 'bag_frac': 0.8421165132560784, 'min_leaf': 99, 'l1': 0.6101911742238941, 'l2': 2.475884550556351}. Best is trial 0 with value: 0.284902134047217.\n",
            "[I 2025-07-07 11:21:28,705] Trial 6 finished with value: 0.5183709679572255 and parameters: {'lr': 0.011085122517311707, 'leaves': 744, 'feat_frac': 0.6293899908000085, 'bag_frac': 0.831261142176991, 'min_leaf': 76, 'l1': 2.600340105889054, 'l2': 2.7335513967163982}. Best is trial 0 with value: 0.284902134047217.\n",
            "[I 2025-07-07 11:21:39,953] Trial 7 finished with value: 0.500515806043585 and parameters: {'lr': 0.017398074711291726, 'leaves': 920, 'feat_frac': 0.8875664116805573, 'bag_frac': 0.9697494707820946, 'min_leaf': 181, 'l1': 2.9894998940554256, 'l2': 4.609371175115584}. Best is trial 0 with value: 0.284902134047217.\n",
            "[I 2025-07-07 11:21:51,970] Trial 8 finished with value: 0.6027161308264828 and parameters: {'lr': 0.01303561122512888, 'leaves': 61, 'feat_frac': 0.522613644455269, 'bag_frac': 0.6626651653816322, 'min_leaf': 90, 'l1': 1.3567451588694794, 'l2': 4.143687545759647}. Best is trial 0 with value: 0.284902134047217.\n",
            "[I 2025-07-07 11:22:00,218] Trial 9 finished with value: 1.7165963088952043 and parameters: {'lr': 0.02911701023242742, 'leaves': 82, 'feat_frac': 0.7713480415791243, 'bag_frac': 0.5704621124873813, 'min_leaf': 165, 'l1': 0.3727532183988541, 'l2': 4.9344346830025865}. Best is trial 0 with value: 0.284902134047217.\n",
            "[I 2025-07-07 11:22:05,422] Trial 10 finished with value: 0.15006918014380177 and parameters: {'lr': 0.046589863196059025, 'leaves': 365, 'feat_frac': 0.9847685553939328, 'bag_frac': 0.9661451709558936, 'min_leaf': 22, 'l1': 1.9902167111008833, 'l2': 0.0757211855137842}. Best is trial 10 with value: 0.15006918014380177.\n",
            "[I 2025-07-07 11:22:12,592] Trial 11 finished with value: 0.1466940757926905 and parameters: {'lr': 0.042987099962655866, 'leaves': 391, 'feat_frac': 0.9987827539727656, 'bag_frac': 0.9968676185612808, 'min_leaf': 21, 'l1': 2.07495575856821, 'l2': 0.14281808621478395}. Best is trial 11 with value: 0.1466940757926905.\n",
            "[I 2025-07-07 11:22:16,314] Trial 12 finished with value: 0.15038201715915686 and parameters: {'lr': 0.06698266383768514, 'leaves': 359, 'feat_frac': 0.9976068260035007, 'bag_frac': 0.9995004182654049, 'min_leaf': 21, 'l1': 1.9379710203198037, 'l2': 0.2250830848923579}. Best is trial 11 with value: 0.1466940757926905.\n",
            "[I 2025-07-07 11:22:24,158] Trial 13 finished with value: 0.2679745304102936 and parameters: {'lr': 0.03289262182892604, 'leaves': 428, 'feat_frac': 0.9789668768648474, 'bag_frac': 0.9302074263985836, 'min_leaf': 63, 'l1': 2.132511570451214, 'l2': 1.4092019390387953}. Best is trial 11 with value: 0.1466940757926905.\n",
            "[I 2025-07-07 11:22:27,240] Trial 14 finished with value: 0.4036339588205967 and parameters: {'lr': 0.07363166019935521, 'leaves': 172, 'feat_frac': 0.9347639033138581, 'bag_frac': 0.8941310020600818, 'min_leaf': 132, 'l1': 3.3170321430599126, 'l2': 1.2396108377546355}. Best is trial 11 with value: 0.1466940757926905.\n",
            "[I 2025-07-07 11:22:29,265] Trial 15 finished with value: 0.2736464242156337 and parameters: {'lr': 0.19106491679598542, 'leaves': 192, 'feat_frac': 0.9323982934150861, 'bag_frac': 0.9040330172235821, 'min_leaf': 43, 'l1': 3.3153035755143145, 'l2': 0.09374157974795039}. Best is trial 11 with value: 0.1466940757926905.\n",
            "[I 2025-07-07 11:22:37,144] Trial 16 finished with value: 0.40642891255619007 and parameters: {'lr': 0.04306359802101975, 'leaves': 489, 'feat_frac': 0.9231289393955415, 'bag_frac': 0.9578998198301658, 'min_leaf': 126, 'l1': 1.9841692228869001, 'l2': 1.8698885287079219}. Best is trial 11 with value: 0.1466940757926905.\n",
            "[I 2025-07-07 11:22:47,968] Trial 17 finished with value: 0.3767796684466214 and parameters: {'lr': 0.050127791050485274, 'leaves': 285, 'feat_frac': 0.8188449590703865, 'bag_frac': 0.8805304594988683, 'min_leaf': 59, 'l1': 0.02370059826544546, 'l2': 0.7190004434253967}. Best is trial 11 with value: 0.1466940757926905.\n",
            "[I 2025-07-07 11:22:54,960] Trial 18 finished with value: 0.2580765019812293 and parameters: {'lr': 0.0252877800294599, 'leaves': 576, 'feat_frac': 0.7224537976722125, 'bag_frac': 0.9840224591320956, 'min_leaf': 20, 'l1': 2.740179587807298, 'l2': 1.8403217981087767}. Best is trial 11 with value: 0.1466940757926905.\n",
            "[I 2025-07-07 11:23:00,704] Trial 19 finished with value: 0.3184284757086471 and parameters: {'lr': 0.041924665069892675, 'leaves': 142, 'feat_frac': 0.9687897636098093, 'bag_frac': 0.7336486130893535, 'min_leaf': 77, 'l1': 3.9793872180099115, 'l2': 0.6480589163421511}. Best is trial 11 with value: 0.1466940757926905.\n",
            "[I 2025-07-07 11:24:34,463] A new study created in memory with name: no-name-df829e9c-bb45-47ee-931c-6c1af7c22254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 BlendProperty5 CV‑MAPE 0.1892\n",
            "\n",
            "🔎 Tuning LightGBM for BlendProperty6 …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-07 11:25:14,675] Trial 0 finished with value: 0.770248605745977 and parameters: {'lr': 0.030710573677773714, 'leaves': 861, 'feat_frac': 0.8659969709057025, 'bag_frac': 0.7993292420985183, 'min_leaf': 48, 'l1': 0.7799726016810132, 'l2': 0.2904180608409973}. Best is trial 0 with value: 0.770248605745977.\n",
            "[I 2025-07-07 11:25:21,346] Trial 1 finished with value: 1.5057896165016564 and parameters: {'lr': 0.13394334706750485, 'leaves': 252, 'feat_frac': 0.8540362888980227, 'bag_frac': 0.5102922471479012, 'min_leaf': 195, 'l1': 4.162213204002109, 'l2': 1.0616955533913808}. Best is trial 0 with value: 0.770248605745977.\n",
            "[I 2025-07-07 11:25:53,683] Trial 2 finished with value: 0.7640302542962092 and parameters: {'lr': 0.017240892195821537, 'leaves': 58, 'feat_frac': 0.6521211214797689, 'bag_frac': 0.762378215816119, 'min_leaf': 98, 'l1': 1.4561457009902097, 'l2': 3.0592644736118975}. Best is trial 2 with value: 0.7640302542962092.\n",
            "[I 2025-07-07 11:26:20,900] Trial 3 finished with value: 0.9988189574488693 and parameters: {'lr': 0.01518747922672247, 'leaves': 85, 'feat_frac': 0.6831809216468459, 'bag_frac': 0.728034992108518, 'min_leaf': 162, 'l1': 0.9983689107917987, 'l2': 2.571172192068058}. Best is trial 2 with value: 0.7640302542962092.\n",
            "[I 2025-07-07 11:26:39,392] Trial 4 finished with value: 0.8367790716349781 and parameters: {'lr': 0.05898602410432694, 'leaves': 36, 'feat_frac': 0.8037724259507192, 'bag_frac': 0.5852620618436457, 'min_leaf': 31, 'l1': 4.7444276862666666, 'l2': 4.828160165372797}. Best is trial 2 with value: 0.7640302542962092.\n",
            "[I 2025-07-07 11:26:50,286] Trial 5 finished with value: 0.8733983132118599 and parameters: {'lr': 0.11265466963346032, 'leaves': 89, 'feat_frac': 0.5488360570031919, 'bag_frac': 0.8421165132560784, 'min_leaf': 99, 'l1': 0.6101911742238941, 'l2': 2.475884550556351}. Best is trial 2 with value: 0.7640302542962092.\n",
            "[I 2025-07-07 11:27:30,973] Trial 6 finished with value: 0.6956159754782549 and parameters: {'lr': 0.011085122517311707, 'leaves': 744, 'feat_frac': 0.6293899908000085, 'bag_frac': 0.831261142176991, 'min_leaf': 76, 'l1': 2.600340105889054, 'l2': 2.7335513967163982}. Best is trial 6 with value: 0.6956159754782549.\n",
            "[I 2025-07-07 11:28:07,515] Trial 7 finished with value: 1.0224884526922575 and parameters: {'lr': 0.017398074711291726, 'leaves': 920, 'feat_frac': 0.8875664116805573, 'bag_frac': 0.9697494707820946, 'min_leaf': 181, 'l1': 2.9894998940554256, 'l2': 4.609371175115584}. Best is trial 6 with value: 0.6956159754782549.\n",
            "[I 2025-07-07 11:28:36,098] Trial 8 finished with value: 0.713038142759468 and parameters: {'lr': 0.01303561122512888, 'leaves': 61, 'feat_frac': 0.522613644455269, 'bag_frac': 0.6626651653816322, 'min_leaf': 90, 'l1': 1.3567451588694794, 'l2': 4.143687545759647}. Best is trial 6 with value: 0.6956159754782549.\n",
            "[I 2025-07-07 11:28:54,763] Trial 9 finished with value: 1.0979173762979035 and parameters: {'lr': 0.02911701023242742, 'leaves': 82, 'feat_frac': 0.7713480415791243, 'bag_frac': 0.5704621124873813, 'min_leaf': 165, 'l1': 0.3727532183988541, 'l2': 4.9344346830025865}. Best is trial 6 with value: 0.6956159754782549.\n",
            "[I 2025-07-07 11:29:10,971] Trial 10 finished with value: 0.8190749272967682 and parameters: {'lr': 0.046589863196059025, 'leaves': 365, 'feat_frac': 0.9847685553939328, 'bag_frac': 0.9352468198873463, 'min_leaf': 135, 'l1': 2.704719540877739, 'l2': 1.8065599822090457}. Best is trial 6 with value: 0.6956159754782549.\n",
            "[I 2025-07-07 11:29:39,938] Trial 11 finished with value: 0.6681822002799405 and parameters: {'lr': 0.010193060666576633, 'leaves': 417, 'feat_frac': 0.5020643883556675, 'bag_frac': 0.6684237691066285, 'min_leaf': 71, 'l1': 2.172895714424139, 'l2': 3.652405312517469}. Best is trial 11 with value: 0.6681822002799405.\n",
            "[I 2025-07-07 11:30:25,574] Trial 12 finished with value: 0.7146452084699075 and parameters: {'lr': 0.010508948475631408, 'leaves': 474, 'feat_frac': 0.6095821487654013, 'bag_frac': 0.8838129988503955, 'min_leaf': 66, 'l1': 1.9379710203198037, 'l2': 3.6775234714403076}. Best is trial 11 with value: 0.6681822002799405.\n",
            "[I 2025-07-07 11:30:46,489] Trial 13 finished with value: 0.7051938779794398 and parameters: {'lr': 0.025872604581846065, 'leaves': 504, 'feat_frac': 0.585668037562274, 'bag_frac': 0.6738167152482912, 'min_leaf': 71, 'l1': 3.1722857018777013, 'l2': 3.409672663616442}. Best is trial 11 with value: 0.6681822002799405.\n",
            "[I 2025-07-07 11:30:53,912] Trial 14 finished with value: 0.853196010649705 and parameters: {'lr': 0.07030578918551263, 'leaves': 182, 'feat_frac': 0.5009308396526463, 'bag_frac': 0.6930177793262874, 'min_leaf': 126, 'l1': 2.0712893672291193, 'l2': 2.00477984841022}. Best is trial 11 with value: 0.6681822002799405.\n",
            "[I 2025-07-07 11:31:50,527] Trial 15 finished with value: 0.7937154261001416 and parameters: {'lr': 0.01056913400085133, 'leaves': 627, 'feat_frac': 0.6895195175992579, 'bag_frac': 0.824051632444964, 'min_leaf': 20, 'l1': 3.39772903754386, 'l2': 3.758067124078944}. Best is trial 11 with value: 0.6681822002799405.\n",
            "[I 2025-07-07 11:32:16,032] Trial 16 finished with value: 0.609650408566461 and parameters: {'lr': 0.022781771141162466, 'leaves': 279, 'feat_frac': 0.5950524787529015, 'bag_frac': 0.6117132442091142, 'min_leaf': 55, 'l1': 2.2563238914893087, 'l2': 2.950108960389427}. Best is trial 16 with value: 0.609650408566461.\n",
            "[I 2025-07-07 11:32:40,421] Trial 17 finished with value: 0.692209210509969 and parameters: {'lr': 0.022768798559957525, 'leaves': 283, 'feat_frac': 0.5617658550398703, 'bag_frac': 0.6046557409514427, 'min_leaf': 51, 'l1': 3.7449462697183797, 'l2': 4.138936297287705}. Best is trial 16 with value: 0.609650408566461.\n",
            "[I 2025-07-07 11:32:57,202] Trial 18 finished with value: 0.6802457423303558 and parameters: {'lr': 0.03963201245202281, 'leaves': 147, 'feat_frac': 0.7247438215188371, 'bag_frac': 0.5130789168552351, 'min_leaf': 45, 'l1': 2.1758684557390833, 'l2': 1.7919514239527086}. Best is trial 16 with value: 0.609650408566461.\n",
            "[I 2025-07-07 11:33:19,873] Trial 19 finished with value: 0.7582136707873295 and parameters: {'lr': 0.019809919808450444, 'leaves': 203, 'feat_frac': 0.5855990712913836, 'bag_frac': 0.6251985006121782, 'min_leaf': 117, 'l1': 1.6374529382141045, 'l2': 3.1370991330748375}. Best is trial 16 with value: 0.609650408566461.\n",
            "[I 2025-07-07 11:34:49,152] A new study created in memory with name: no-name-8a15dfe6-4be0-4f61-8baa-6d2f42a5d476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 BlendProperty6 CV‑MAPE 0.9778\n",
            "\n",
            "🔎 Tuning LightGBM for BlendProperty7 …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-07 11:35:25,350] Trial 0 finished with value: 1.074504177066251 and parameters: {'lr': 0.030710573677773714, 'leaves': 861, 'feat_frac': 0.8659969709057025, 'bag_frac': 0.7993292420985183, 'min_leaf': 48, 'l1': 0.7799726016810132, 'l2': 0.2904180608409973}. Best is trial 0 with value: 1.074504177066251.\n",
            "[I 2025-07-07 11:35:30,266] Trial 1 finished with value: 2.6568336039023412 and parameters: {'lr': 0.13394334706750485, 'leaves': 252, 'feat_frac': 0.8540362888980227, 'bag_frac': 0.5102922471479012, 'min_leaf': 195, 'l1': 4.162213204002109, 'l2': 1.0616955533913808}. Best is trial 0 with value: 1.074504177066251.\n",
            "[I 2025-07-07 11:35:59,358] Trial 2 finished with value: 1.4746805919000512 and parameters: {'lr': 0.017240892195821537, 'leaves': 58, 'feat_frac': 0.6521211214797689, 'bag_frac': 0.762378215816119, 'min_leaf': 98, 'l1': 1.4561457009902097, 'l2': 3.0592644736118975}. Best is trial 0 with value: 1.074504177066251.\n",
            "[I 2025-07-07 11:36:28,193] Trial 3 finished with value: 1.6603565680334842 and parameters: {'lr': 0.01518747922672247, 'leaves': 85, 'feat_frac': 0.6831809216468459, 'bag_frac': 0.728034992108518, 'min_leaf': 162, 'l1': 0.9983689107917987, 'l2': 2.571172192068058}. Best is trial 0 with value: 1.074504177066251.\n",
            "[I 2025-07-07 11:36:42,255] Trial 4 finished with value: 0.9330008114229275 and parameters: {'lr': 0.05898602410432694, 'leaves': 36, 'feat_frac': 0.8037724259507192, 'bag_frac': 0.5852620618436457, 'min_leaf': 31, 'l1': 4.7444276862666666, 'l2': 4.828160165372797}. Best is trial 4 with value: 0.9330008114229275.\n",
            "[I 2025-07-07 11:36:49,163] Trial 5 finished with value: 1.5394754459163207 and parameters: {'lr': 0.11265466963346032, 'leaves': 89, 'feat_frac': 0.5488360570031919, 'bag_frac': 0.8421165132560784, 'min_leaf': 99, 'l1': 0.6101911742238941, 'l2': 2.475884550556351}. Best is trial 4 with value: 0.9330008114229275.\n",
            "[I 2025-07-07 11:37:25,615] Trial 6 finished with value: 1.2916856608478162 and parameters: {'lr': 0.011085122517311707, 'leaves': 744, 'feat_frac': 0.6293899908000085, 'bag_frac': 0.831261142176991, 'min_leaf': 76, 'l1': 2.600340105889054, 'l2': 2.7335513967163982}. Best is trial 4 with value: 0.9330008114229275.\n",
            "[I 2025-07-07 11:38:00,116] Trial 7 finished with value: 1.4405979274060812 and parameters: {'lr': 0.017398074711291726, 'leaves': 920, 'feat_frac': 0.8875664116805573, 'bag_frac': 0.9697494707820946, 'min_leaf': 181, 'l1': 2.9894998940554256, 'l2': 4.609371175115584}. Best is trial 4 with value: 0.9330008114229275.\n",
            "[I 2025-07-07 11:38:25,385] Trial 8 finished with value: 1.266305632164784 and parameters: {'lr': 0.01303561122512888, 'leaves': 61, 'feat_frac': 0.522613644455269, 'bag_frac': 0.6626651653816322, 'min_leaf': 90, 'l1': 1.3567451588694794, 'l2': 4.143687545759647}. Best is trial 4 with value: 0.9330008114229275.\n",
            "[I 2025-07-07 11:38:40,855] Trial 9 finished with value: 2.176664132512509 and parameters: {'lr': 0.02911701023242742, 'leaves': 82, 'feat_frac': 0.7713480415791243, 'bag_frac': 0.5704621124873813, 'min_leaf': 165, 'l1': 0.3727532183988541, 'l2': 4.9344346830025865}. Best is trial 4 with value: 0.9330008114229275.\n",
            "[I 2025-07-07 11:38:52,707] Trial 10 finished with value: 1.1957739860743097 and parameters: {'lr': 0.06773954610088083, 'leaves': 31, 'feat_frac': 0.9847685553939328, 'bag_frac': 0.6248126654205948, 'min_leaf': 22, 'l1': 4.538323976412588, 'l2': 3.6518344760350483}. Best is trial 4 with value: 0.9330008114229275.\n",
            "[I 2025-07-07 11:39:11,823] Trial 11 finished with value: 0.823893647942071 and parameters: {'lr': 0.04615891548857443, 'leaves': 276, 'feat_frac': 0.8218563683119118, 'bag_frac': 0.9172592880976009, 'min_leaf': 21, 'l1': 3.456902056583494, 'l2': 0.3028582949201123}. Best is trial 11 with value: 0.823893647942071.\n",
            "[I 2025-07-07 11:39:17,781] Trial 12 finished with value: 1.4064383991139793 and parameters: {'lr': 0.060026600811284275, 'leaves': 276, 'feat_frac': 0.7813218493142023, 'bag_frac': 0.9989895177184265, 'min_leaf': 21, 'l1': 3.748322645768217, 'l2': 1.531779373019332}. Best is trial 11 with value: 0.823893647942071.\n",
            "[I 2025-07-07 11:39:29,087] Trial 13 finished with value: 1.1880572096133069 and parameters: {'lr': 0.08130729020285374, 'leaves': 459, 'feat_frac': 0.9359103949481631, 'bag_frac': 0.9073278540513456, 'min_leaf': 49, 'l1': 4.974648750565031, 'l2': 0.09154739119468014}. Best is trial 11 with value: 0.823893647942071.\n",
            "[I 2025-07-07 11:39:47,843] Trial 14 finished with value: 1.3682041372337799 and parameters: {'lr': 0.04107294297376663, 'leaves': 162, 'feat_frac': 0.8088564833889003, 'bag_frac': 0.696503887746367, 'min_leaf': 132, 'l1': 3.3784210319608428, 'l2': 1.7397219643362183}. Best is trial 11 with value: 0.823893647942071.\n",
            "[I 2025-07-07 11:39:53,008] Trial 15 finished with value: 1.279988480146304 and parameters: {'lr': 0.19249283313481994, 'leaves': 144, 'feat_frac': 0.7214795649377084, 'bag_frac': 0.9040330172235821, 'min_leaf': 55, 'l1': 2.0670704984635635, 'l2': 3.6011867831440494}. Best is trial 11 with value: 0.823893647942071.\n",
            "[I 2025-07-07 11:40:06,604] Trial 16 finished with value: 1.8140880266379553 and parameters: {'lr': 0.042954687853520405, 'leaves': 415, 'feat_frac': 0.8223026474772008, 'bag_frac': 0.5836460058929472, 'min_leaf': 126, 'l1': 3.9689202994764567, 'l2': 1.068433462710018}. Best is trial 11 with value: 0.823893647942071.\n",
            "[I 2025-07-07 11:40:23,171] Trial 17 finished with value: 1.7590558740032616 and parameters: {'lr': 0.028664226134463386, 'leaves': 257, 'feat_frac': 0.7320832480224756, 'bag_frac': 0.5028815366736693, 'min_leaf': 64, 'l1': 4.9356356618371615, 'l2': 2.0850736746159964}. Best is trial 11 with value: 0.823893647942071.\n",
            "[I 2025-07-07 11:40:34,658] Trial 18 finished with value: 0.9495627812884095 and parameters: {'lr': 0.0895100809933199, 'leaves': 33, 'feat_frac': 0.920268595864156, 'bag_frac': 0.9298249375977756, 'min_leaf': 33, 'l1': 3.165271469660913, 'l2': 0.8599982788701318}. Best is trial 11 with value: 0.823893647942071.\n",
            "[I 2025-07-07 11:40:47,395] Trial 19 finished with value: 0.9891188101368599 and parameters: {'lr': 0.056096019406980634, 'leaves': 128, 'feat_frac': 0.9659084100735005, 'bag_frac': 0.8617560480723552, 'min_leaf': 75, 'l1': 4.436327425966383, 'l2': 3.4506504844135395}. Best is trial 11 with value: 0.823893647942071.\n",
            "[I 2025-07-07 11:42:19,050] A new study created in memory with name: no-name-aaf5acac-af3a-4d23-9650-48214e129c88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 BlendProperty7 CV‑MAPE 1.0538\n",
            "\n",
            "🔎 Tuning LightGBM for BlendProperty8 …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-07 11:43:01,353] Trial 0 finished with value: 0.9728030443853044 and parameters: {'lr': 0.030710573677773714, 'leaves': 861, 'feat_frac': 0.8659969709057025, 'bag_frac': 0.7993292420985183, 'min_leaf': 48, 'l1': 0.7799726016810132, 'l2': 0.2904180608409973}. Best is trial 0 with value: 0.9728030443853044.\n",
            "[I 2025-07-07 11:43:06,230] Trial 1 finished with value: 1.7316871855150127 and parameters: {'lr': 0.13394334706750485, 'leaves': 252, 'feat_frac': 0.8540362888980227, 'bag_frac': 0.5102922471479012, 'min_leaf': 195, 'l1': 4.162213204002109, 'l2': 1.0616955533913808}. Best is trial 0 with value: 0.9728030443853044.\n",
            "[I 2025-07-07 11:43:40,103] Trial 2 finished with value: 1.0065191754535183 and parameters: {'lr': 0.017240892195821537, 'leaves': 58, 'feat_frac': 0.6521211214797689, 'bag_frac': 0.762378215816119, 'min_leaf': 98, 'l1': 1.4561457009902097, 'l2': 3.0592644736118975}. Best is trial 0 with value: 0.9728030443853044.\n",
            "[I 2025-07-07 11:44:04,803] Trial 3 finished with value: 1.1183571519246385 and parameters: {'lr': 0.01518747922672247, 'leaves': 85, 'feat_frac': 0.6831809216468459, 'bag_frac': 0.728034992108518, 'min_leaf': 162, 'l1': 0.9983689107917987, 'l2': 2.571172192068058}. Best is trial 0 with value: 0.9728030443853044.\n",
            "[I 2025-07-07 11:44:19,870] Trial 4 finished with value: 1.0725829321127294 and parameters: {'lr': 0.05898602410432694, 'leaves': 36, 'feat_frac': 0.8037724259507192, 'bag_frac': 0.5852620618436457, 'min_leaf': 31, 'l1': 4.7444276862666666, 'l2': 4.828160165372797}. Best is trial 0 with value: 0.9728030443853044.\n",
            "[I 2025-07-07 11:44:28,723] Trial 5 finished with value: 1.0600415027547783 and parameters: {'lr': 0.11265466963346032, 'leaves': 89, 'feat_frac': 0.5488360570031919, 'bag_frac': 0.8421165132560784, 'min_leaf': 99, 'l1': 0.6101911742238941, 'l2': 2.475884550556351}. Best is trial 0 with value: 0.9728030443853044.\n",
            "[I 2025-07-07 11:45:07,083] Trial 6 finished with value: 0.8660865789419763 and parameters: {'lr': 0.011085122517311707, 'leaves': 744, 'feat_frac': 0.6293899908000085, 'bag_frac': 0.831261142176991, 'min_leaf': 76, 'l1': 2.600340105889054, 'l2': 2.7335513967163982}. Best is trial 6 with value: 0.8660865789419763.\n",
            "[I 2025-07-07 11:45:42,722] Trial 7 finished with value: 1.108330213216724 and parameters: {'lr': 0.017398074711291726, 'leaves': 920, 'feat_frac': 0.8875664116805573, 'bag_frac': 0.9697494707820946, 'min_leaf': 181, 'l1': 2.9894998940554256, 'l2': 4.609371175115584}. Best is trial 6 with value: 0.8660865789419763.\n",
            "[I 2025-07-07 11:46:08,400] Trial 8 finished with value: 1.001505344252274 and parameters: {'lr': 0.01303561122512888, 'leaves': 61, 'feat_frac': 0.522613644455269, 'bag_frac': 0.6626651653816322, 'min_leaf': 90, 'l1': 1.3567451588694794, 'l2': 4.143687545759647}. Best is trial 6 with value: 0.8660865789419763.\n",
            "[I 2025-07-07 11:46:20,975] Trial 9 finished with value: 1.275658561739096 and parameters: {'lr': 0.02911701023242742, 'leaves': 82, 'feat_frac': 0.7713480415791243, 'bag_frac': 0.5704621124873813, 'min_leaf': 165, 'l1': 0.3727532183988541, 'l2': 4.9344346830025865}. Best is trial 6 with value: 0.8660865789419763.\n",
            "[I 2025-07-07 11:46:43,520] Trial 10 finished with value: 1.0077109095893353 and parameters: {'lr': 0.046589863196059025, 'leaves': 365, 'feat_frac': 0.9847685553939328, 'bag_frac': 0.9352468198873463, 'min_leaf': 135, 'l1': 2.704719540877739, 'l2': 1.8065599822090457}. Best is trial 6 with value: 0.8660865789419763.\n",
            "[I 2025-07-07 11:47:13,364] Trial 11 finished with value: 0.8363273933050266 and parameters: {'lr': 0.02898154369216274, 'leaves': 960, 'feat_frac': 0.659116748316145, 'bag_frac': 0.844814020142349, 'min_leaf': 45, 'l1': 2.144275627354273, 'l2': 0.3028582949201123}. Best is trial 11 with value: 0.8363273933050266.\n",
            "[I 2025-07-07 11:47:44,882] Trial 12 finished with value: 0.8398335180418401 and parameters: {'lr': 0.027901244948523092, 'leaves': 483, 'feat_frac': 0.6396470776224414, 'bag_frac': 0.8743432904199808, 'min_leaf': 66, 'l1': 1.9379710203198037, 'l2': 3.413191351346504}. Best is trial 11 with value: 0.8363273933050266.\n",
            "[I 2025-07-07 11:48:10,730] Trial 13 finished with value: 0.7977553289701383 and parameters: {'lr': 0.02816812451825095, 'leaves': 459, 'feat_frac': 0.5930798685488915, 'bag_frac': 0.8995959176426559, 'min_leaf': 62, 'l1': 2.018398472270893, 'l2': 3.5598890110670576}. Best is trial 13 with value: 0.7977553289701383.\n",
            "[I 2025-07-07 11:48:26,560] Trial 14 finished with value: 1.0484380235846555 and parameters: {'lr': 0.07030578918551263, 'leaves': 472, 'feat_frac': 0.5863594791887671, 'bag_frac': 0.9201476488100833, 'min_leaf': 24, 'l1': 3.3170321430599126, 'l2': 0.24095748032972308}. Best is trial 13 with value: 0.7977553289701383.\n",
            "[I 2025-07-07 11:48:55,080] Trial 15 finished with value: 0.8187982481024427 and parameters: {'lr': 0.025314405479538452, 'leaves': 202, 'feat_frac': 0.7109381852713446, 'bag_frac': 0.9948558532035325, 'min_leaf': 55, 'l1': 1.998514422161182, 'l2': 3.758067124078944}. Best is trial 13 with value: 0.7977553289701383.\n",
            "[I 2025-07-07 11:49:07,287] Trial 16 finished with value: 0.9469812517197773 and parameters: {'lr': 0.08602348547993806, 'leaves': 161, 'feat_frac': 0.7261631564388041, 'bag_frac': 0.9920205711849168, 'min_leaf': 124, 'l1': 2.007486410720169, 'l2': 3.6521187731573246}. Best is trial 13 with value: 0.7977553289701383.\n",
            "[I 2025-07-07 11:49:27,036] Trial 17 finished with value: 0.9679630277518371 and parameters: {'lr': 0.040533460367131104, 'leaves': 155, 'feat_frac': 0.7177633870610598, 'bag_frac': 0.913217399679865, 'min_leaf': 64, 'l1': 3.5351658725771733, 'l2': 4.031808385764467}. Best is trial 13 with value: 0.7977553289701383.\n",
            "[I 2025-07-07 11:49:59,118] Trial 18 finished with value: 0.8082266666119946 and parameters: {'lr': 0.021423421601430438, 'leaves': 237, 'feat_frac': 0.5851844040992087, 'bag_frac': 0.9825953589394048, 'min_leaf': 46, 'l1': 1.6116747611101734, 'l2': 1.7919514239527086}. Best is trial 13 with value: 0.7977553289701383.\n",
            "[I 2025-07-07 11:50:33,833] Trial 19 finished with value: 0.7456005133220102 and parameters: {'lr': 0.021697349162289915, 'leaves': 303, 'feat_frac': 0.5811748247839448, 'bag_frac': 0.895890947296417, 'min_leaf': 82, 'l1': 1.3928571256614362, 'l2': 1.8276409712581954}. Best is trial 19 with value: 0.7456005133220102.\n",
            "[I 2025-07-07 11:52:02,846] A new study created in memory with name: no-name-8db161ff-ce39-49b8-98a2-f08c963b44c2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 BlendProperty8 CV‑MAPE 1.2821\n",
            "\n",
            "🔎 Tuning LightGBM for BlendProperty9 …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-07 11:52:42,270] Trial 0 finished with value: 1.6255211577583595 and parameters: {'lr': 0.030710573677773714, 'leaves': 861, 'feat_frac': 0.8659969709057025, 'bag_frac': 0.7993292420985183, 'min_leaf': 48, 'l1': 0.7799726016810132, 'l2': 0.2904180608409973}. Best is trial 0 with value: 1.6255211577583595.\n",
            "[I 2025-07-07 11:52:46,970] Trial 1 finished with value: 1.5486771190443327 and parameters: {'lr': 0.13394334706750485, 'leaves': 252, 'feat_frac': 0.8540362888980227, 'bag_frac': 0.5102922471479012, 'min_leaf': 195, 'l1': 4.162213204002109, 'l2': 1.0616955533913808}. Best is trial 1 with value: 1.5486771190443327.\n",
            "[I 2025-07-07 11:53:11,476] Trial 2 finished with value: 1.5891425295459616 and parameters: {'lr': 0.017240892195821537, 'leaves': 58, 'feat_frac': 0.6521211214797689, 'bag_frac': 0.762378215816119, 'min_leaf': 98, 'l1': 1.4561457009902097, 'l2': 3.0592644736118975}. Best is trial 1 with value: 1.5486771190443327.\n",
            "[I 2025-07-07 11:53:29,175] Trial 3 finished with value: 1.9371104523200642 and parameters: {'lr': 0.01518747922672247, 'leaves': 85, 'feat_frac': 0.6831809216468459, 'bag_frac': 0.728034992108518, 'min_leaf': 162, 'l1': 0.9983689107917987, 'l2': 2.571172192068058}. Best is trial 1 with value: 1.5486771190443327.\n",
            "[I 2025-07-07 11:53:39,649] Trial 4 finished with value: 1.4020016903496313 and parameters: {'lr': 0.05898602410432694, 'leaves': 36, 'feat_frac': 0.8037724259507192, 'bag_frac': 0.5852620618436457, 'min_leaf': 31, 'l1': 4.7444276862666666, 'l2': 4.828160165372797}. Best is trial 4 with value: 1.4020016903496313.\n",
            "[I 2025-07-07 11:53:48,065] Trial 5 finished with value: 1.5193113087981547 and parameters: {'lr': 0.11265466963346032, 'leaves': 89, 'feat_frac': 0.5488360570031919, 'bag_frac': 0.8421165132560784, 'min_leaf': 99, 'l1': 0.6101911742238941, 'l2': 2.475884550556351}. Best is trial 4 with value: 1.4020016903496313.\n",
            "[I 2025-07-07 11:54:21,587] Trial 6 finished with value: 1.288628011635062 and parameters: {'lr': 0.011085122517311707, 'leaves': 744, 'feat_frac': 0.6293899908000085, 'bag_frac': 0.831261142176991, 'min_leaf': 76, 'l1': 2.600340105889054, 'l2': 2.7335513967163982}. Best is trial 6 with value: 1.288628011635062.\n",
            "[I 2025-07-07 11:54:55,294] Trial 7 finished with value: 1.9430336236055923 and parameters: {'lr': 0.017398074711291726, 'leaves': 920, 'feat_frac': 0.8875664116805573, 'bag_frac': 0.9697494707820946, 'min_leaf': 181, 'l1': 2.9894998940554256, 'l2': 4.609371175115584}. Best is trial 6 with value: 1.288628011635062.\n",
            "[I 2025-07-07 11:55:18,234] Trial 8 finished with value: 1.6144693169648257 and parameters: {'lr': 0.01303561122512888, 'leaves': 61, 'feat_frac': 0.522613644455269, 'bag_frac': 0.6626651653816322, 'min_leaf': 90, 'l1': 1.3567451588694794, 'l2': 4.143687545759647}. Best is trial 6 with value: 1.288628011635062.\n",
            "[I 2025-07-07 11:55:29,461] Trial 9 finished with value: 1.9936283997878679 and parameters: {'lr': 0.02911701023242742, 'leaves': 82, 'feat_frac': 0.7713480415791243, 'bag_frac': 0.5704621124873813, 'min_leaf': 165, 'l1': 0.3727532183988541, 'l2': 4.9344346830025865}. Best is trial 6 with value: 1.288628011635062.\n",
            "[I 2025-07-07 11:55:44,272] Trial 10 finished with value: 2.2062549859990654 and parameters: {'lr': 0.046589863196059025, 'leaves': 365, 'feat_frac': 0.9847685553939328, 'bag_frac': 0.9352468198873463, 'min_leaf': 135, 'l1': 2.704719540877739, 'l2': 1.8065599822090457}. Best is trial 6 with value: 1.288628011635062.\n",
            "[I 2025-07-07 11:55:53,910] Trial 11 finished with value: 1.0830850131371386 and parameters: {'lr': 0.06761147179060022, 'leaves': 34, 'feat_frac': 0.65522484496423, 'bag_frac': 0.640380477119852, 'min_leaf': 21, 'l1': 4.636538152672896, 'l2': 3.827244067518126}. Best is trial 11 with value: 1.0830850131371386.\n",
            "[I 2025-07-07 11:56:01,706] Trial 12 finished with value: 1.2845944281963246 and parameters: {'lr': 0.07297448422270648, 'leaves': 469, 'feat_frac': 0.6396470776224414, 'bag_frac': 0.8838129988503955, 'min_leaf': 59, 'l1': 3.5321668866102103, 'l2': 3.542157932952742}. Best is trial 11 with value: 1.0830850131371386.\n",
            "[I 2025-07-07 11:56:13,532] Trial 13 finished with value: 1.5719918454591384 and parameters: {'lr': 0.07890611278819241, 'leaves': 446, 'feat_frac': 0.5907884540226088, 'bag_frac': 0.9026683119805237, 'min_leaf': 60, 'l1': 3.859647918800966, 'l2': 3.5598890110670576}. Best is trial 11 with value: 1.0830850131371386.\n",
            "[I 2025-07-07 11:56:20,107] Trial 14 finished with value: 1.8948517046133255 and parameters: {'lr': 0.18141111135220764, 'leaves': 165, 'feat_frac': 0.7088720199581395, 'bag_frac': 0.6644821816821105, 'min_leaf': 24, 'l1': 4.988248733576324, 'l2': 3.631185963286396}. Best is trial 11 with value: 1.0830850131371386.\n",
            "[I 2025-07-07 11:56:27,065] Trial 15 finished with value: 1.5027725992124024 and parameters: {'lr': 0.07803396992021194, 'leaves': 200, 'feat_frac': 0.7322885530266395, 'bag_frac': 0.6731508062971927, 'min_leaf': 55, 'l1': 3.5889760042637042, 'l2': 3.758067124078944}. Best is trial 11 with value: 1.0830850131371386.\n",
            "[I 2025-07-07 11:56:44,602] Trial 16 finished with value: 1.5494729842546646 and parameters: {'lr': 0.0319076754025076, 'leaves': 489, 'feat_frac': 0.5969821391628446, 'bag_frac': 0.8791118085065369, 'min_leaf': 126, 'l1': 3.3821086831858547, 'l2': 1.8698885287079219}. Best is trial 11 with value: 1.0830850131371386.\n",
            "[I 2025-07-07 11:56:51,312] Trial 17 finished with value: 1.3496209911484613 and parameters: {'lr': 0.08045975633786878, 'leaves': 130, 'feat_frac': 0.6747805645356216, 'bag_frac': 0.7246299402248966, 'min_leaf': 41, 'l1': 4.350346729814932, 'l2': 4.177427877857041}. Best is trial 11 with value: 1.0830850131371386.\n",
            "[I 2025-07-07 11:57:08,614] Trial 18 finished with value: 1.2615625993544584 and parameters: {'lr': 0.05137430180577585, 'leaves': 33, 'feat_frac': 0.5044876753576464, 'bag_frac': 0.6007807225857327, 'min_leaf': 20, 'l1': 1.9438459739319307, 'l2': 3.100744538922787}. Best is trial 11 with value: 1.0830850131371386.\n",
            "[I 2025-07-07 11:57:23,267] Trial 19 finished with value: 0.9416287964794767 and parameters: {'lr': 0.04889815123914749, 'leaves': 31, 'feat_frac': 0.5108567256343721, 'bag_frac': 0.5975779944351961, 'min_leaf': 21, 'l1': 1.9009136319305533, 'l2': 1.9620393718147173}. Best is trial 19 with value: 0.9416287964794767.\n",
            "[I 2025-07-07 11:58:53,028] A new study created in memory with name: no-name-58358948-06dd-4f4e-9343-22b8c05e7281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 BlendProperty9 CV‑MAPE 1.4258\n",
            "\n",
            "🔎 Tuning LightGBM for BlendProperty10 …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-07 11:59:32,899] Trial 0 finished with value: 0.5217880412416893 and parameters: {'lr': 0.030710573677773714, 'leaves': 861, 'feat_frac': 0.8659969709057025, 'bag_frac': 0.7993292420985183, 'min_leaf': 48, 'l1': 0.7799726016810132, 'l2': 0.2904180608409973}. Best is trial 0 with value: 0.5217880412416893.\n",
            "[I 2025-07-07 11:59:41,634] Trial 1 finished with value: 1.120072847786486 and parameters: {'lr': 0.13394334706750485, 'leaves': 252, 'feat_frac': 0.8540362888980227, 'bag_frac': 0.5102922471479012, 'min_leaf': 195, 'l1': 4.162213204002109, 'l2': 1.0616955533913808}. Best is trial 0 with value: 0.5217880412416893.\n",
            "[I 2025-07-07 12:00:13,481] Trial 2 finished with value: 0.6158098441268212 and parameters: {'lr': 0.017240892195821537, 'leaves': 58, 'feat_frac': 0.6521211214797689, 'bag_frac': 0.762378215816119, 'min_leaf': 98, 'l1': 1.4561457009902097, 'l2': 3.0592644736118975}. Best is trial 0 with value: 0.5217880412416893.\n",
            "[I 2025-07-07 12:00:36,165] Trial 3 finished with value: 0.7989175784163619 and parameters: {'lr': 0.01518747922672247, 'leaves': 85, 'feat_frac': 0.6831809216468459, 'bag_frac': 0.728034992108518, 'min_leaf': 162, 'l1': 0.9983689107917987, 'l2': 2.571172192068058}. Best is trial 0 with value: 0.5217880412416893.\n",
            "[I 2025-07-07 12:00:49,262] Trial 4 finished with value: 0.6587243697234252 and parameters: {'lr': 0.05898602410432694, 'leaves': 36, 'feat_frac': 0.8037724259507192, 'bag_frac': 0.5852620618436457, 'min_leaf': 31, 'l1': 4.7444276862666666, 'l2': 4.828160165372797}. Best is trial 0 with value: 0.5217880412416893.\n",
            "[I 2025-07-07 12:00:58,147] Trial 5 finished with value: 0.6877268464143759 and parameters: {'lr': 0.11265466963346032, 'leaves': 89, 'feat_frac': 0.5488360570031919, 'bag_frac': 0.8421165132560784, 'min_leaf': 99, 'l1': 0.6101911742238941, 'l2': 2.475884550556351}. Best is trial 0 with value: 0.5217880412416893.\n",
            "[I 2025-07-07 12:01:28,480] Trial 6 finished with value: 0.5458796298588521 and parameters: {'lr': 0.011085122517311707, 'leaves': 744, 'feat_frac': 0.6293899908000085, 'bag_frac': 0.831261142176991, 'min_leaf': 76, 'l1': 2.600340105889054, 'l2': 2.7335513967163982}. Best is trial 0 with value: 0.5217880412416893.\n",
            "[I 2025-07-07 12:02:00,443] Trial 7 finished with value: 0.7197872878379801 and parameters: {'lr': 0.017398074711291726, 'leaves': 920, 'feat_frac': 0.8875664116805573, 'bag_frac': 0.9697494707820946, 'min_leaf': 181, 'l1': 2.9894998940554256, 'l2': 4.609371175115584}. Best is trial 0 with value: 0.5217880412416893.\n",
            "[I 2025-07-07 12:02:24,856] Trial 8 finished with value: 0.5849654774167341 and parameters: {'lr': 0.01303561122512888, 'leaves': 61, 'feat_frac': 0.522613644455269, 'bag_frac': 0.6626651653816322, 'min_leaf': 90, 'l1': 1.3567451588694794, 'l2': 4.143687545759647}. Best is trial 0 with value: 0.5217880412416893.\n",
            "[I 2025-07-07 12:02:40,608] Trial 9 finished with value: 0.8500369345070486 and parameters: {'lr': 0.02911701023242742, 'leaves': 82, 'feat_frac': 0.7713480415791243, 'bag_frac': 0.5704621124873813, 'min_leaf': 165, 'l1': 0.3727532183988541, 'l2': 4.9344346830025865}. Best is trial 0 with value: 0.5217880412416893.\n",
            "[I 2025-07-07 12:03:03,978] Trial 10 finished with value: 0.6248823982781369 and parameters: {'lr': 0.046589863196059025, 'leaves': 365, 'feat_frac': 0.9847685553939328, 'bag_frac': 0.9661451709558936, 'min_leaf': 22, 'l1': 1.9902167111008833, 'l2': 0.0757211855137842}. Best is trial 0 with value: 0.5217880412416893.\n",
            "[I 2025-07-07 12:03:24,012] Trial 11 finished with value: 0.558381469813621 and parameters: {'lr': 0.02898154369216274, 'leaves': 960, 'feat_frac': 0.659116748316145, 'bag_frac': 0.8591901910708761, 'min_leaf': 64, 'l1': 3.0703077922696456, 'l2': 1.4611923275099303}. Best is trial 0 with value: 0.5217880412416893.\n",
            "[I 2025-07-07 12:04:16,432] Trial 12 finished with value: 0.48940561859297615 and parameters: {'lr': 0.010739952383430782, 'leaves': 483, 'feat_frac': 0.9490222375504709, 'bag_frac': 0.8364610680219806, 'min_leaf': 59, 'l1': 2.3412281186577166, 'l2': 3.427172407696691}. Best is trial 12 with value: 0.48940561859297615.\n",
            "[I 2025-07-07 12:04:45,790] Trial 13 finished with value: 0.5174187331994426 and parameters: {'lr': 0.07890559538527207, 'leaves': 470, 'feat_frac': 0.9713744804067912, 'bag_frac': 0.8981900652883728, 'min_leaf': 54, 'l1': 0.09972409271247584, 'l2': 3.5598890110670576}. Best is trial 12 with value: 0.48940561859297615.\n",
            "[I 2025-07-07 12:04:59,316] Trial 14 finished with value: 0.6700361584815904 and parameters: {'lr': 0.07030578918551263, 'leaves': 474, 'feat_frac': 0.9996812193207756, 'bag_frac': 0.919480421162128, 'min_leaf': 132, 'l1': 3.5374927829709866, 'l2': 3.6433393182258587}. Best is trial 12 with value: 0.48940561859297615.\n",
            "[I 2025-07-07 12:05:06,051] Trial 15 finished with value: 0.7273770592243127 and parameters: {'lr': 0.19765072745196458, 'leaves': 200, 'feat_frac': 0.9332049821844495, 'bag_frac': 0.9019321993175599, 'min_leaf': 125, 'l1': 2.0321456696176705, 'l2': 3.6697671882446374}. Best is trial 12 with value: 0.48940561859297615.\n",
            "[I 2025-07-07 12:05:25,789] Trial 16 finished with value: 0.5390388528419677 and parameters: {'lr': 0.09218058143728766, 'leaves': 489, 'feat_frac': 0.9141215508614347, 'bag_frac': 0.7127947321819145, 'min_leaf': 54, 'l1': 0.02169162618146829, 'l2': 1.941353372836316}. Best is trial 12 with value: 0.48940561859297615.\n",
            "[I 2025-07-07 12:05:36,058] Trial 17 finished with value: 0.6521296757053912 and parameters: {'lr': 0.04053350614212214, 'leaves': 315, 'feat_frac': 0.9482119160562965, 'bag_frac': 0.9985629687000506, 'min_leaf': 42, 'l1': 3.7661903543164286, 'l2': 3.4111115319807146}. Best is trial 12 with value: 0.48940561859297615.\n",
            "[I 2025-07-07 12:06:11,177] Trial 18 finished with value: 0.5367440651524233 and parameters: {'lr': 0.021423421601430438, 'leaves': 147, 'feat_frac': 0.8146643330149076, 'bag_frac': 0.8859917261640172, 'min_leaf': 75, 'l1': 1.9438459739319307, 'l2': 4.134769533878438}. Best is trial 12 with value: 0.48940561859297615.\n",
            "[I 2025-07-07 12:06:22,833] Trial 19 finished with value: 0.7269410870520295 and parameters: {'lr': 0.07436902054944462, 'leaves': 575, 'feat_frac': 0.7230725210374479, 'bag_frac': 0.7907936823065363, 'min_leaf': 123, 'l1': 4.916537598109273, 'l2': 4.069968527889158}. Best is trial 12 with value: 0.48940561859297615.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 BlendProperty10 CV‑MAPE 0.7001\n",
            "\n",
            "📈 Mean CV‑MAPE over all targets: 1.3637\n",
            "\n",
            "✅ Submission saved to “lightgbm_optuna_submission.csv”\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.model_selection import KFold\n",
        "import xgboost as xgb\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "#  Load data\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "X = train.iloc[:, :55].copy()\n",
        "y = train.iloc[:, 55:]\n",
        "test_X = test.iloc[:, :55].copy()\n",
        "if 'ID' in test.columns:\n",
        "    test_X = test.drop(columns=['ID']).copy()\n",
        "\n",
        "# Features\n",
        "for prop_num in [2, 3]:\n",
        "    cols = [f'Component{i}_Property{prop_num}' for i in range(1,6)]\n",
        "    X[f'Avg_Property{prop_num}'] = X[cols].mean(axis=1)\n",
        "    test_X[f'Avg_Property{prop_num}'] = test_X[cols].mean(axis=1)\n",
        "\n",
        "for prop_num in range(1, 11):\n",
        "    comp_props = [f'Component{i}_Property{prop_num}' for i in range(1,6)]\n",
        "    comp_fracs = [f'Component{i}_fraction' for i in range(1,6)]\n",
        "    X[f'WeightedAvg_Property{prop_num}'] = sum(\n",
        "        X[frac] * X[prop] for frac, prop in zip(comp_fracs, comp_props))\n",
        "    test_X[f'WeightedAvg_Property{prop_num}'] = sum(\n",
        "        test_X[frac] * test_X[prop] for frac, prop in zip(comp_fracs, comp_props))\n",
        "\n",
        "#  KFold for stacking\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Arrays to collect out-of-fold predictions (for train) and test predictions\n",
        "meta_train = np.zeros((X.shape[0], 10*5))  # 5 base models × 10 targets\n",
        "meta_test = np.zeros((test_X.shape[0], 10*5))\n",
        "\n",
        "# Base models\n",
        "base_models = [\n",
        "    ('xgb', MultiOutputRegressor(xgb.XGBRegressor(\n",
        "        n_estimators=500, max_depth=6, learning_rate=0.05,\n",
        "        subsample=0.8, colsample_bytree=0.8, eval_metric='mae',\n",
        "        random_state=42, verbosity=0))),\n",
        "    ('lgb', MultiOutputRegressor(LGBMRegressor(\n",
        "        n_estimators=400, max_depth=6, learning_rate=0.05,\n",
        "        subsample=0.8, colsample_bytree=0.8, random_state=42, verbose=-1))),\n",
        "    ('rf', MultiOutputRegressor(RandomForestRegressor(\n",
        "        n_estimators=300, max_depth=8, min_samples_leaf=4, random_state=42))),\n",
        "    ('ridge', MultiOutputRegressor(Ridge())),\n",
        "    ('cat', MultiOutputRegressor(CatBoostRegressor(\n",
        "        verbose=0, iterations=500, depth=6, learning_rate=0.05, random_seed=42)))\n",
        "]\n",
        "\n",
        "# Out-of-fold predictions\n",
        "for idx, (name, model) in enumerate(base_models):\n",
        "    print(f\"✅ Training base model: {name}\")\n",
        "    test_preds_fold = np.zeros((test_X.shape[0], 10, 5))  # test preds per fold\n",
        "\n",
        "    for fold, (train_idx, valid_idx) in enumerate(kf.split(X)):\n",
        "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
        "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        meta_train[valid_idx, idx*10:(idx+1)*10] = model.predict(X_valid)\n",
        "        test_preds_fold[:, :, fold] = model.predict(test_X)\n",
        "\n",
        "    # Average test preds across folds\n",
        "    meta_test[:, idx*10:(idx+1)*10] = test_preds_fold.mean(axis=2)\n",
        "\n",
        "print(\" Meta features shape:\", meta_train.shape, meta_test.shape)\n",
        "\n",
        "#  Meta-model: simple Ridge (works well)\n",
        "meta_model = MultiOutputRegressor(Ridge())\n",
        "meta_model.fit(meta_train, y)\n",
        "meta_train_preds = meta_model.predict(meta_train)\n",
        "meta_test_preds = meta_model.predict(meta_test)\n",
        "\n",
        "#  Evaluate\n",
        "stacking_mape = mean_absolute_percentage_error(y, meta_train_preds)\n",
        "print(\"✅ Stacking train MAPE:\", stacking_mape)\n",
        "\n",
        "# Save submission\n",
        "submission = pd.DataFrame(\n",
        "    meta_test_preds,\n",
        "    columns=[f\"BlendProperty{i}\" for i in range(1, 11)]\n",
        ")\n",
        "if 'ID' in test.columns:\n",
        "    submission.insert(0, 'ID', test['ID'])\n",
        "submission.to_csv(\"submission_stacking.csv\", index=False)\n",
        "print(\" submission_stacking.csv saved! Shape:\", submission.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSqx_VMyyOh3",
        "outputId": "65953073-efd7-4ed8-d1df-ddd066cedadd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Training base model: xgb\n",
            "✅ Training base model: lgb\n",
            "✅ Training base model: rf\n",
            "✅ Training base model: ridge\n",
            "✅ Training base model: cat\n",
            " Meta features shape: (2000, 50) (500, 50)\n",
            "✅ Stacking train MAPE: 0.8456449423069339\n",
            " submission_stacking.csv saved! Shape: (500, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
        "from sklearn.linear_model import Ridge, ElasticNet\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "import xgboost as xgb\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load data\n",
        "print(\"📊 Loading data...\")\n",
        "train = pd.read_csv(\"/content/train.csv\")\n",
        "test = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "X = train.iloc[:, :55].copy()\n",
        "y = train.iloc[:, 55:].copy()\n",
        "test_X = test.iloc[:, :55].copy()\n",
        "\n",
        "if 'ID' in test.columns:\n",
        "    test_X = test.drop(columns=['ID']).copy()\n",
        "\n",
        "print(f\"Train shape: {X.shape}, Test shape: {test_X.shape}\")\n",
        "\n",
        "# ================================\n",
        "# ENHANCED FEATURE ENGINEERING\n",
        "# ================================\n",
        "\n",
        "def create_advanced_features(df):\n",
        "    \"\"\"Create advanced features for better prediction\"\"\"\n",
        "\n",
        "    # Original features\n",
        "    for prop_num in [2, 3]:\n",
        "        cols = [f'Component{i}_Property{prop_num}' for i in range(1,6)]\n",
        "        df[f'Avg_Property{prop_num}'] = df[cols].mean(axis=1)\n",
        "\n",
        "    for prop_num in range(1, 11):\n",
        "        comp_props = [f'Component{i}_Property{prop_num}' for i in range(1,6)]\n",
        "        comp_fracs = [f'Component{i}_fraction' for i in range(1,6)]\n",
        "        df[f'WeightedAvg_Property{prop_num}'] = sum(\n",
        "            df[frac] * df[prop] for frac, prop in zip(comp_fracs, comp_props))\n",
        "\n",
        "    # NEW ADVANCED FEATURES\n",
        "\n",
        "    # 1. Interaction features between components\n",
        "    for i in range(1, 6):\n",
        "        for j in range(i+1, 6):\n",
        "            df[f'Interaction_C{i}_C{j}'] = df[f'Component{i}_fraction'] * df[f'Component{j}_fraction']\n",
        "\n",
        "    # 2. Variance and standard deviation of properties\n",
        "    for prop_num in range(1, 11):\n",
        "        cols = [f'Component{i}_Property{prop_num}' for i in range(1,6)]\n",
        "        df[f'Std_Property{prop_num}'] = df[cols].std(axis=1)\n",
        "        df[f'Var_Property{prop_num}'] = df[cols].var(axis=1)\n",
        "        df[f'Range_Property{prop_num}'] = df[cols].max(axis=1) - df[cols].min(axis=1)\n",
        "\n",
        "    # 3. Ratios between dominant components\n",
        "    fraction_cols = [f'Component{i}_fraction' for i in range(1,6)]\n",
        "    df['Max_fraction'] = df[fraction_cols].max(axis=1)\n",
        "    df['Min_fraction'] = df[fraction_cols].min(axis=1)\n",
        "    df['Fraction_ratio'] = df['Max_fraction'] / (df['Min_fraction'] + 1e-8)\n",
        "\n",
        "    # 4. Component dominance features\n",
        "    for i in range(1, 6):\n",
        "        df[f'Component{i}_dominance'] = df[f'Component{i}_fraction'] / df['Max_fraction']\n",
        "\n",
        "    # 5. Weighted moments\n",
        "    for prop_num in range(1, 11):\n",
        "        comp_props = [f'Component{i}_Property{prop_num}' for i in range(1,6)]\n",
        "        comp_fracs = [f'Component{i}_fraction' for i in range(1,6)]\n",
        "\n",
        "        # Second moment (variance-like)\n",
        "        weighted_avg = df[f'WeightedAvg_Property{prop_num}']\n",
        "        weighted_var = sum(df[frac] * (df[prop] - weighted_avg)**2\n",
        "                          for frac, prop in zip(comp_fracs, comp_props))\n",
        "        df[f'WeightedVar_Property{prop_num}'] = weighted_var\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply feature engineering\n",
        "print(\"🔧 Creating advanced features...\")\n",
        "X = create_advanced_features(X)\n",
        "test_X = create_advanced_features(test_X)\n",
        "\n",
        "print(f\"After feature engineering - Train: {X.shape}, Test: {test_X.shape}\")\n",
        "\n",
        "# ================================\n",
        "# FEATURE SCALING AND SELECTION\n",
        "# ================================\n",
        "\n",
        "# Scale features\n",
        "scaler = RobustScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index)\n",
        "test_X_scaled = pd.DataFrame(scaler.transform(test_X), columns=test_X.columns, index=test_X.index)\n",
        "\n",
        "# Feature selection based on target correlation\n",
        "print(\"📈 Performing feature selection...\")\n",
        "selector = SelectKBest(score_func=f_regression, k=min(200, X_scaled.shape[1]))\n",
        "X_selected = selector.fit_transform(X_scaled, y.mean(axis=1))  # Use mean target for selection\n",
        "test_X_selected = selector.transform(test_X_scaled)\n",
        "\n",
        "# Get selected feature names\n",
        "selected_features = X_scaled.columns[selector.get_support()]\n",
        "print(f\"Selected {len(selected_features)} features out of {X_scaled.shape[1]}\")\n",
        "\n",
        "# ================================\n",
        "# IMPROVED CROSS-VALIDATION\n",
        "# ================================\n",
        "\n",
        "# Use stratified k-fold based on target binning\n",
        "def create_stratified_target(y_data, n_bins=5):\n",
        "    \"\"\"Create stratified target for better CV splits\"\"\"\n",
        "    target_mean = y_data.mean(axis=1)\n",
        "    bins = pd.cut(target_mean, bins=n_bins, labels=False)\n",
        "    return bins\n",
        "\n",
        "stratify_target = create_stratified_target(y)\n",
        "kf = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)  # More folds\n",
        "\n",
        "# ================================\n",
        "# ENHANCED BASE MODELS\n",
        "# ================================\n",
        "\n",
        "base_models = [\n",
        "    ('xgb', MultiOutputRegressor(xgb.XGBRegressor(\n",
        "        n_estimators=800, max_depth=7, learning_rate=0.03,\n",
        "        subsample=0.85, colsample_bytree=0.85, eval_metric='mae',\n",
        "        reg_alpha=0.1, reg_lambda=0.1, random_state=42, verbosity=0))),\n",
        "\n",
        "    ('lgb', MultiOutputRegressor(LGBMRegressor(\n",
        "        n_estimators=600, max_depth=7, learning_rate=0.03,\n",
        "        subsample=0.85, colsample_bytree=0.85, reg_alpha=0.1, reg_lambda=0.1,\n",
        "        random_state=42, verbose=-1))),\n",
        "\n",
        "    ('rf', MultiOutputRegressor(RandomForestRegressor(\n",
        "        n_estimators=400, max_depth=10, min_samples_leaf=3,\n",
        "        max_features='sqrt', random_state=42))),\n",
        "\n",
        "    ('et', MultiOutputRegressor(ExtraTreesRegressor(\n",
        "        n_estimators=400, max_depth=10, min_samples_leaf=3,\n",
        "        max_features='sqrt', random_state=42))),\n",
        "\n",
        "    ('ridge', MultiOutputRegressor(Ridge(alpha=1.0))),\n",
        "\n",
        "    ('elastic', MultiOutputRegressor(ElasticNet(alpha=0.1, l1_ratio=0.5))),\n",
        "\n",
        "    ('cat', MultiOutputRegressor(CatBoostRegressor(\n",
        "        verbose=0, iterations=600, depth=7, learning_rate=0.03,\n",
        "        reg_lambda=0.1, random_seed=42)))\n",
        "]\n",
        "\n",
        "n_models = len(base_models)\n",
        "n_targets = y.shape[1]\n",
        "n_folds = 7\n",
        "\n",
        "# Arrays for meta-features\n",
        "meta_train = np.zeros((X.shape[0], n_models * n_targets))\n",
        "meta_test = np.zeros((test_X.shape[0], n_models * n_targets))\n",
        "\n",
        "print(f\"🚀 Training {n_models} base models with {n_folds}-fold CV...\")\n",
        "\n",
        "# Generate out-of-fold predictions\n",
        "for idx, (name, model) in enumerate(base_models):\n",
        "    print(f\"Training {name}...\")\n",
        "\n",
        "    test_preds_fold = np.zeros((test_X.shape[0], n_targets, n_folds))\n",
        "\n",
        "    for fold, (train_idx, valid_idx) in enumerate(kf.split(X_selected, stratify_target)):\n",
        "        X_train, X_valid = X_selected[train_idx], X_selected[valid_idx]\n",
        "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Out-of-fold predictions\n",
        "        valid_preds = model.predict(X_valid)\n",
        "        meta_train[valid_idx, idx*n_targets:(idx+1)*n_targets] = valid_preds\n",
        "\n",
        "        # Test predictions\n",
        "        test_preds_fold[:, :, fold] = model.predict(test_X_selected)\n",
        "\n",
        "    # Average test predictions across folds\n",
        "    meta_test[:, idx*n_targets:(idx+1)*n_targets] = test_preds_fold.mean(axis=2)\n",
        "\n",
        "print(f\"✅ Meta-features shape: {meta_train.shape}\")\n",
        "\n",
        "# ================================\n",
        "# ADVANCED META-MODEL\n",
        "# ================================\n",
        "\n",
        "# Try multiple meta-models and ensemble them\n",
        "meta_models = [\n",
        "    ('ridge', MultiOutputRegressor(Ridge(alpha=0.1))),\n",
        "    ('elastic', MultiOutputRegressor(ElasticNet(alpha=0.01, l1_ratio=0.5))),\n",
        "    ('lgb_meta', MultiOutputRegressor(LGBMRegressor(\n",
        "        n_estimators=100, max_depth=4, learning_rate=0.1,\n",
        "        verbose=-1, random_state=42)))\n",
        "]\n",
        "\n",
        "meta_predictions = []\n",
        "meta_scores = []\n",
        "\n",
        "for name, meta_model in meta_models:\n",
        "    print(f\"Training meta-model: {name}\")\n",
        "\n",
        "    # Scale meta-features\n",
        "    meta_scaler = StandardScaler()\n",
        "    meta_train_scaled = meta_scaler.fit_transform(meta_train)\n",
        "    meta_test_scaled = meta_scaler.transform(meta_test)\n",
        "\n",
        "    meta_model.fit(meta_train_scaled, y)\n",
        "    meta_pred = meta_model.predict(meta_train_scaled)\n",
        "    meta_test_pred = meta_model.predict(meta_test_scaled)\n",
        "\n",
        "    score = mean_absolute_percentage_error(y, meta_pred)\n",
        "    print(f\"{name} MAPE: {score:.4f}\")\n",
        "\n",
        "    meta_predictions.append(meta_test_pred)\n",
        "    meta_scores.append(score)\n",
        "\n",
        "# Weighted ensemble of meta-models\n",
        "weights = np.array([1/score for score in meta_scores])\n",
        "weights = weights / weights.sum()\n",
        "\n",
        "print(f\"Meta-model weights: {dict(zip([name for name, _ in meta_models], weights))}\")\n",
        "\n",
        "# Final prediction as weighted average\n",
        "final_prediction = np.average(meta_predictions, axis=0, weights=weights)\n",
        "\n",
        "# ================================\n",
        "# EVALUATION AND SUBMISSION\n",
        "# ================================\n",
        "\n",
        "# Best single meta-model for evaluation\n",
        "best_idx = np.argmin(meta_scores)\n",
        "best_meta_model = meta_models[best_idx][1]\n",
        "meta_scaler = StandardScaler()\n",
        "meta_train_scaled = meta_scaler.fit_transform(meta_train)\n",
        "best_meta_model.fit(meta_train_scaled, y)\n",
        "best_pred = best_meta_model.predict(meta_train_scaled)\n",
        "\n",
        "print(f\"\\n🎯 Best meta-model: {meta_models[best_idx][0]}\")\n",
        "print(f\"Best single meta-model MAPE: {meta_scores[best_idx]:.4f}\")\n",
        "\n",
        "# Create submission\n",
        "submission = pd.DataFrame(\n",
        "    final_prediction,\n",
        "    columns=[f\"BlendProperty{i}\" for i in range(1, 11)]\n",
        ")\n",
        "\n",
        "if 'ID' in test.columns:\n",
        "    submission.insert(0, 'ID', test['ID'])\n",
        "\n",
        "submission.to_csv(\"submission_enhanced_stacking.csv\", index=False)\n",
        "print(f\"\\n✅ Enhanced submission saved! Shape: {submission.shape}\")\n",
        "print(\"📁 File: submission_enhanced_stacking.csv\")\n",
        "\n",
        "# Additional diagnostics\n",
        "print(f\"\\n📊 Model Performance Summary:\")\n",
        "print(f\"Number of base models: {n_models}\")\n",
        "print(f\"Number of meta-features: {meta_train.shape[1]}\")\n",
        "print(f\"Cross-validation folds: {n_folds}\")\n",
        "print(f\"Final features used: {len(selected_features)}\")\n",
        "print(f\"Meta-model ensemble weights: {weights}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiOXZ_m9-pFG",
        "outputId": "a7e77cb1-7831-426f-dc39-fa7aed5a6318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Loading data...\n",
            "Train shape: (2000, 55), Test shape: (500, 55)\n",
            "🔧 Creating advanced features...\n",
            "After feature engineering - Train: (2000, 125), Test: (500, 125)\n",
            "📈 Performing feature selection...\n",
            "Selected 125 features out of 125\n",
            "🚀 Training 7 base models with 7-fold CV...\n",
            "Training xgb...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOD4IYvoCmNODDXKPOLPg7M",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}